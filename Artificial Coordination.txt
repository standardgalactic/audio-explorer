The Age of Artiﬁcial Coordination
Optimization, Entropy, and the Collapse of Conserved Meaning
Flyxion
January 25, 2026
Abstract
This paper argues that the contemporary collapse of digital quality, trust, and
pedagogy is not a cultural or ethical failure but an architectural one. When identity,
reputation, and history become costless to discard, social and informational systems
lose the ability to accumulate meaning over time. Under these conditions, optimization
no longer operates on agents embedded in continuity, but on transient artifacts compet-
ing for attention in a memoryless substrate. Metrics detach from substance, learning
is displaced by imitation, and simulation systematically outcompetes participation.
Using concepts from information theory and thermodynamics, the paper formal-
izes identity as a conserved state variable required for non-zero mutual information
between agents and actions. It shows how "namespace laundering" drives this mutual
information toward zero, producing a high-entropy equilibrium characterized by metric
gaming, synthetic spectacle, and what is termed the fake junk spiral. Extending the
analysis beyond platforms, the paper treats interfaces, borders, and bureaucracies as
energetic costs imposed by trust failure. It concludes by identifying invariant design
principles required for counter-entropic systems capable of conserving meaning under
optimization pressure.
1

1
Introduction: Identity, Information, and Architec-
tural Failure
The contemporary degradation of digital content is frequently described in cultural or moral
terms: declining attention spans, generational preference shifts, the corrupting inﬂuence of
automation, or the irresponsible deployment of artiﬁcial intelligence.
Such explanations,
while intuitively appealing, obscure the more fundamental nature of the transformation cur-
rently underway. What is occurring is not a failure of taste, nor a lapse in ethical discipline,
but an architectural phase transition. The governing constraints of the digital environment
have changed, and with them, the selection pressures acting on human behavior.
This essay advances the thesis that the observed collapse of quality, trust, and pedagog-
ical integrity in digital systems follows directly from the systematic destruction of identity
continuity. When identity is decoupled from history—when names, accounts, reputations,
and roles become costless to discard and regenerate—the system loses the ability to accumu-
late meaning over time. In such an environment, optimization no longer operates on agents
embedded in history, but on isolated artifacts competing for transient attention. The result
is an entropy-dominated regime characterized by high-velocity spectacle, metric gaming, and
the displacement of learning by imitation.
The argument proceeds in three stages. First, we formalize the relationship between
identity and information accumulation, showing that meaning requires a stateful observer
whose actions remain mutually informative across time. Second, we analyze the mechanics
of namespace laundering—the process by which platforms render identity disposable—and
demonstrate how this detaches metrics from substance. Third, we show that once identity
conservation fails, optimization inevitably selects for high-arousal, low-cost artifacts, pro-
ducing what may be described as a fake junk spiral: a self-reinforcing equilibrium in which
simulation outcompetes participation.
The goal of this analysis is not reformist. No appeal is made for better behavior, improved
moderation, or more responsible users. Instead, the essay treats digital platforms as physical
systems governed by conservation laws, feedback loops, and thermodynamic constraints.
Where these constraints are violated, entropy increases. Where invariants are not enforced,
meaning decays.
2

2
Identity as a Conserved Quantity
Information theory provides a precise vocabulary for distinguishing between signal accumu-
lation and noise proliferation. Consider a system composed of agents A, actions X, and
observers O. Meaning arises when the observer can infer properties of the agent from ob-
served actions. Formally, this requires non-zero mutual information I(A; X), deﬁned as:
I(A; X) =
X
a∈A
X
x∈X
p(a, x) log p(a, x)
p(a)p(x).
(1)
In social systems with conserved identity, this mutual information accumulates over time.
An agents past actions condition expectations about future behavior, allowing observers
to discount noise, detect fraud, and reward durable contribution. Identity, in this sense,
functions analogously to state in a dynamical system: it is the memory that allows successive
observations to cohere.
Crucially, identity conservation is not a moral property but a structural one. It requires
that actions be irrevocably associated with the same agent across time, and that abandoning
this association incur non-trivial cost. In physical systems, such costs arise naturally from
inertia, energy expenditure, and irreversibility. In social systems, they arise from reputation,
accountability, and the diﬃculty of re-entry after failure.
When identity is conserved, optimization remains bounded.
An agent attempting to
maximize short-term gain at the expense of long-term trust faces a tradeoﬀ, as future oppor-
tunities depend on historical coherence. Under these conditions, metrics such as approval,
visibility, or inﬂuence function as imperfect but usable proxies for quality.
3
Namespace Laundering and the Destruction of Mu-
tual Information
Namespace laundering occurs when a system permits agents to sever the link between past
and present identity at negligible cost. This may take the form of disposable accounts, ef-
fortless rebranding, automated page creation, or identity abstraction layers that treat names
as interchangeable tokens. The deﬁning characteristic is not anonymity per se, but non-
persistence: the ability to abandon history without consequence.
Formally, namespace laundering drives the conditional distribution p(x | a) toward inde-
pendence. As identities churn, the joint distribution factorizes:
p(a, x) →p(a)p(x),
(2)
3

and mutual information collapses:
I(A; X) →0.
(3)
At this point, metrics attached to actions lose their evaluative meaning. A view, like, or
share no longer represents an update about a stable producer; it is merely a transient scalar
attached to a disposable artifact. Optimization thus shifts domains: instead of improving
agent behavior over time, it targets the production of artifacts that locally maximize metric
extraction.
This transition has a critical consequence. Once identities are disposable, the system
becomes blind to recidivism. Patterns of low-quality output, manipulation, or fabrication
cannot be tracked, because each instance appears statistically independent. Forgetting is no
longer a failure mode; it is an operational requirement for throughput. Liquidity is prioritized
over continuity, and the system structurally rewards churn.
From the platforms perspective, this architecture is rational. Low-friction identity cre-
ation maximizes participation and content supply. However, it also eliminates the conditions
under which meaning can be conserved. The system consumes attention—an energetically
costly cognitive resource—but produces no durable work product. It becomes, in thermody-
namic terms, an information sink.
4
Optimization After Identity Failure
Once identity conservation fails, optimization dynamics undergo a qualitative change. Met-
rics remain, but they no longer correspond to properties of agents. They instead measure
the instantaneous eﬀectiveness of artifacts in capturing attention. Goodharts Law applies in
its strongest form: when a measure becomes a target without an anchored subject, it ceases
to measure quality altogether.
Under these conditions, selection pressure favors strategies that maximize metric yield
per unit time and cost. Durability, coherence, and truth impose unnecessary constraints and
are therefore outcompeted. The system converges toward high-velocity artifacts optimized
for a memoryless audience.
Such artifacts share predictable properties. They minimize required context, maximize
arousal, and exploit evolutionarily conserved response mechanisms. Content appealing to
fear, sexual interest, cuteness, or outrage bypasses deliberative cognition, producing rapid
engagement independent of trust or expertise. These strategies are not cultural pathologies;
they are equilibrium solutions under the given constraints.
4

At the limit, the distinction between participation and simulation collapses. Because the
system does not reward the accumulation of competence, producing a convincing imitation
of activity becomes strictly more eﬃcient than engaging in the activity itself. Fabrication
is not merely tolerated; it is optimal. The resulting environment is dominated by recycled
motifs, synthetic personas, and artifacts whose sole function is to satisfy algorithmic ﬁlters.
This dynamic constitutes what may be called the fake junk spiral. As signal quality de-
clines, actors must produce increasingly extreme stimuli to achieve the same metric response.
Metrics inﬂate, trust collapses, and the cost of genuine contribution becomes prohibitive. The
system does not fail catastrophically; it asymptotically approaches a high-entropy equilib-
rium in which meaning cannot accumulate.
5
Thermodynamics of Attention and Entropy Produc-
tion
The dynamics described above admit a natural thermodynamic interpretation. Digital plat-
forms are not abstract informational spaces; they are physical systems instantiated on energy-
consuming hardware, coupled to biological agents whose cognitive capacities are ﬁnite and
metabolically expensive. Attention, in this context, functions as a scarce thermodynamic
resource. It is expended to reduce uncertainty, integrate information, and update internal
models of the world. Any system that persistently absorbs attention without producing
durable informational structure behaves analogously to a heat engine operating at zero net
work.
Claude Shannons formalization of information as entropy provides a starting point. Let a
stream of digital artifacts be modeled as a random process Xt. The entropy rate H(X) mea-
sures the average uncertainty per symbol. In a system that accumulates meaning, successive
symbols are correlated; redundancy encodes structure, and entropy rate is bounded. In con-
trast, a system optimized for novelty and churn drives toward maximal entropy production,
minimizing predictability and thereby maximizing short-term engagement.
Landauers principle establishes that the erasure of information has an irreducible ener-
getic cost. Each bit of lost state requires the dissipation of heat. While digital systems
externalize this cost to hardware and power grids, cognitive systems internalize it. The con-
tinual presentation of uncorrelated, high-arousal stimuli forces repeated model resets in the
observer. Memory is overwritten rather than reﬁned. The subjective experience is fatigue,
confusion, and diminished capacity for sustained reasoning.
Platforms that permit identity laundering exacerbate this process by eliminating long-
5

range correlations. When identities are non-persistent, content streams lose historical coher-
ence. The entropy rate approaches that of white noise modulated only by low-level biological
triggers. The observers learning rate collapses, not because information is absent, but be-
cause information cannot be integrated.
This condition may be described as the heat death of meaning. Just as thermodynamic
equilibrium corresponds to maximal entropy and minimal free energy, the digital equilibrium
under laundering corresponds to maximal stimulus ﬂux and minimal semantic work. The
system remains active, even frenetic, but no structure accumulates. Attention is converted
entirely into waste heat.
6
Generative Artiﬁcial Intelligence as an Entropy Ac-
celerator
The introduction of generative artiﬁcial intelligence does not alter these dynamics at a fun-
damental level; rather, it accelerates them by lowering the energetic barrier to artifact pro-
duction. Generative models function as entropy compressors during training and entropy
expanders during deployment. They internalize statistical regularities of large corpora, then
emit plausible continuations at negligible marginal cost.
In a conserved-identity system, such tools might function as productivity ampliﬁers,
assisting agents whose work remains anchored to external constraints. In a laundering envi-
ronment, however, generative systems remove the ﬁnal coupling between eﬀort and output.
The cost diﬀerential between participation and simulation collapses.
Formally, let Cr denote the cost of real participation in a domain requiring skill acqui-
sition, practice, and error correction, and let Cs denote the cost of producing a synthetic
approximation suﬃcient to trigger engagement metrics. In a physically grounded system,
Cs ≥Cr, as fabrication requires expertise comparable to the activity being simulated. Gen-
erative AI in a laundering environment drives Cs ≪Cr. Under rational optimization, agents
select fabrication.
The consequence is not merely an increase in low-quality content, but a structural ambi-
guity between signal and hallucination. When outputs are no longer traceable to persistent
agents or external ground truth, the system loses the ability to discriminate between error,
deception, and stochastic noise. The distinction between a human mistake and an automated
fabrication becomes irrelevant, as neither carries historical consequence.
This ambiguity further accelerates entropy production. As trust collapses, actors respond
by increasing output volume and stimulus intensity, compounding the fake junk spiral. Gen-
6

erative AI thus functions as an entropy accelerator not because it is inherently deceptive,
but because it is deployed in an architecture that has already abandoned conservation laws.
7
The New Pedagogy: Optimization Without Learn-
ing
The degradation of content quality is accompanied by a corresponding collapse of pedagogy.
In a conserved system, learning is cumulative. Skills build upon prior competencies, and
failure provides information that guides future eﬀort. Instruction presupposes continuity:
the learner is expected to persist through diﬃculty, accumulate practice, and internalize
constraints.
In a laundering environment, this structure dissolves.
Time spent acquiring durable
skills competes directly with time spent optimizing visibility. Because optimization produces
immediate metric feedback while learning produces delayed and uncertain rewards, rational
agents divert eﬀort toward meta-optimization. The system begins to teach not how to do
things, but how to appear as though things are being done.
This constitutes a form of null pedagogy. Platforms explicitly instruct users in posting
frequency, trend exploitation, metric interpretation, and tool orchestration. These lessons
are internally coherent but externally sterile. They do not generalize beyond the platform,
nor do they transfer to domains governed by physical constraints. Learning is displaced by
imitation, and competence is replaced by ﬂuency in manipulation.
The critical feature of null pedagogy is that failure is hidden rather than exposed. Low-
performing artifacts are buried, not analyzed. The system learns nothing from error because
error leaves no trace. Progress is decoupled from outcome, and advancement is gated only
by continued participation. Under such conditions, the pedagogical function of diﬃculty
disappears. Nothing resists.
8
Ground Truth and the Collapse of External Con-
straint
A deﬁning characteristic of the laundering regime is the severance of digital success from
external reality. In domains such as engineering, logistics, or chemistry, outcomes are con-
strained by material law. A structure either stands or collapses; a reaction proceeds or fails;
a delivery arrives or does not. Metrics in such domains are subordinate to ground truth.
7

In contrast, social platforms increasingly operate with purely internal metrics. Visibility,
engagement, and inﬂuence are measured without reference to external consequence. When
these metrics dominate, fabrication becomes indistinguishable from achievement. A success-
ful simulation is rewarded more reliably than an unsuccessful attempt at reality.
This inversion has profound implications. It trains agents to prefer controllable sym-
bols over uncontrollable facts. The cost of failure in reality exceeds the cost of failure in
simulation, while the rewards are reversed. Over time, participation in physically grounded
domains appears irrational relative to symbolic optimization.
The result is a widening participation gap. Activities essential to civilizational maintenance—
repair, infrastructure upkeep, deep technical learning—receive minimal engagement because
they do not map cleanly onto platform metrics. These activities are slow, local, and re-
sistant to commodiﬁcation. They require identity continuity and tolerate failure only as a
precondition for mastery.
9
Civilizational Maintenance and the Accumulation Gap
Civilizations persist not through constant innovation, but through maintenance.
Roads,
power grids, factories, and knowledge systems degrade unless continuously repaired. Main-
tenance is characteristically low-visibility and high-cost. It produces stability rather than
novelty and therefore fares poorly in attention-optimized environments.
When identity and eﬀort are not conserved, maintenance work is systematically under-
valued. The skills required to perform it are diﬃcult to acquire and impossible to simulate
convincingly without real engagement. As a result, the attention economy functions para-
sitically, drawing cognitive resources away from maintenance while contributing nothing to
its execution.
This produces an accumulation gap. Knowledge that cannot be algorithmically formal-
ized or rapidly transmitted fails to propagate. Apprenticeship structures erode, tacit skills
vanish, and institutional memory decays. The system remains informationally active but
materially fragile.
10
The Choice of Invariants
The analysis presented here admits no behavioral remedy. The observed phenomena are
not the result of poor incentives layered atop an otherwise sound architecture; they are the
direct consequence of violating fundamental conservation laws. When identity is disposable,
8

eﬀort is not conserved. When eﬀort is not conserved, meaning cannot accumulate. When
meaning cannot accumulate, optimization converges toward entropy.
The choice, therefore, is architectural. Systems of surface maximize liquidity, throughput,
and symbolic velocity at the cost of coherence. Systems of substance enforce continuity,
impose cost, and preserve the distinction between doing and simulating. The former converge
toward perpetual forgetting; the latter permit accumulation.
The current digital environment has elected to optimize for the speed of the symbol. Any
alternative must instead optimize for the integrity of the object. This requires enforceable
continuity, visible failure, thermodynamic accountability, and anchoring to external ground
truth. Without these invariants, no amount of moderation, education, or ethical exhortation
can arrest the spiral.
What follows from this conclusion is not another critique, but a design problem. The ques-
tion is no longer why the system fails, but where it leaks. Only by rebuilding the substrate—
factories, platforms, workﬂows—under constraints that resist laundering can meaning be
conserved.
11
From Indictment to Construction: The Role of In-
variants
Having established that the degradation of digital meaning is an architectural consequence
of violated conservation laws, the analysis must now change register. The appropriate re-
sponse to an entropy engine is not exhortation but redesign. In physical systems, stability
is not achieved by encouraging particles to behave better, but by imposing constraints that
shape allowable trajectories. The same principle applies here. Any counterfactual digital
architecture capable of accumulating meaning must be deﬁned, ﬁrst and foremost, by its
invariants.
An invariant, in this context, is a property of the system that remains preserved under
all admissible operations. Invariant-preserving transformations allow change without loss
of structure; invariant-violating transformations produce entropy. The design problem is
therefore to identify which quantities must be conserved in order for learning, trust, and
competence to remain possible, and to embed these conservation laws at the lowest possible
level of the system.
Four such invariants emerge from the preceding analysis: the conservation of eﬀort, the
visibility of failure, thermodynamic accountability, and anchoring to external ground truth.
Each addresses a distinct leakage mode in existing platforms. Together, they deﬁne the min-
9

imum conditions under which optimization selects for participation rather than simulation.
12
Conservation of Eﬀort
The ﬁrst invariant concerns eﬀort. In any system where meaningful work is to be distin-
guished from noise, eﬀort must leave an irreversible trace. In physical labor, this trace is
obvious: time passes, energy is expended, materials are transformed. In many digital sys-
tems, however, eﬀort is abstracted away. Actions are symbolically equivalent regardless of
the work required to produce them.
This abstraction enables laundering. If a post generated by sustained practice and a post
generated by automated synthesis carry identical weight in the system, rational agents will
select the cheaper path. The invariant required to prevent this collapse is that eﬀort must
be conserved: outputs must remain provably coupled to the expenditure of time, energy, or
constrained resources.
One formal approach is to distinguish between reports and logs. A report is a symbolic
summary that may be fabricated without reference to the underlying process. A log is an
append-only record of events whose structure encodes irreversibility. In distributed systems,
logs are privileged precisely because they cannot be rewritten without detection. In physical
systems, logs are written into matter itself.
Let E(t) denote cumulative eﬀort as a function of time, and let O denote observable
outputs. In a laundering environment, O is independent of E(t). Conservation requires
enforcing a monotonic relationship:
∂O
∂E > 0,
(4)
with a lower bound that prevents arbitrary ampliﬁcation. This does not require that all
eﬀort be rewarded equally, but it does require that zero-eﬀort outputs be structurally disad-
vantaged.
Practical implementations may include proof-of-history mechanisms, rate limits tied to
identity age, or cryptographic proofs of elapsed time. In non-digital domains, such con-
straints already exist implicitly. The design challenge is to reintroduce them where abstrac-
tion has erased them.
13
Visibility of Failure
Eﬀort conservation alone is insuﬃcient if failure is hidden. Learning requires error signals
that persist long enough to shape future behavior. In laundering environments, failure is
10

erased through suppression, deletion, or metric burial. The system thereby deprives itself of
negative information and repeats the same low-quality patterns indeﬁnitely.
Visibility of failure is therefore a second invariant. This does not imply public shaming
or punitive exposure, but structural persistence. Failed attempts must remain legible to
the system and to the agent. In engineering, this function is served by inspection reports,
incident logs, and postmortems. In education, it is served by prerequisites and mastery
thresholds.
Formally, let a process consist of states S0, S1, . . . , Sn connected by transitions contingent
on demonstrated outcomes. A feed-based system allows arbitrary skipping:
Si →Sj
∀i, j.
(5)
A failure-visible system restricts transitions:
Si →Si+1
iﬀoutcome(Si) ≥θ,
(6)
where θ is a veriﬁable competence threshold.
This structure converts pedagogy from exposure to progression. Advancement becomes
conditional on outcomes rather than participation. Importantly, such gating does not require
centralized judgment; it requires only that outcomes be recorded and preserved.
14
Thermodynamic Accountability
The third invariant concerns entropy production.
In current platforms, there is no cost
associated with producing noise.
Attention is treated as an inexhaustible sink, and the
energetic burden of processing low-quality content is externalized to users. This violates
basic thermodynamic intuition. Systems that dissipate energy without producing work are
unstable.
Thermodynamic accountability requires modeling attention as a ﬁnite resource and noise
as a liability. One approach is to deﬁne a signal-to-entropy ratio σ for agents or processes:
σ = Iuseful
Htotal
,
(7)
where Iuseful denotes information that contributes to cumulative structure, and Htotal denotes
total entropy introduced.
Processes whose σ falls below a threshold must be throttled, cooled, or rate-limited.
11

This mirrors physical systems in which heat dissipation constrains throughput. Importantly,
throttling is not punitive; it is stabilizing. It prevents runaway oscillation and preserves the
capacity for meaningful work.
15
Anchoring to External Ground Truth
The ﬁnal invariant is anchoring. No purely symbolic system can enforce truth internally once
optimization pressure intensiﬁes. External constraints are required. In physical production,
these constraints are provided by sensors, measurements, and material limits. A dashboard
may claim success, but the power meter must agree.
Digital systems capable of conserving meaning must therefore integrate external veriﬁ-
cation wherever possible. This may include physical sensors, supply-chain attestations, or
other mechanisms that bind symbolic claims to irreducible facts. The key requirement is
asymmetry: it must be easier to perform the real action than to fake its trace.
Let S denote symbolic state and G denote ground truth. Conservation requires:
P(S | G) ≫P(S | ¬G),
(8)
ensuring that truthful states dominate under optimization.
16
Design Under Adversarial Pressure
These invariants deﬁne a design space, not a ﬁnished system. Any proposed architecture
must be stress-tested under adversarial assumptions. The guiding question is not whether
the system works under good faith, but whether it leaks under optimization.
This marks a decisive shift in method. The task is no longer to persuade, but to constrain.
Where persuasion fails, physics succeeds.
17
Schematic Thinking
The collapse of digital meaning cannot be reversed by better narratives or improved moder-
ation. It can only be addressed by restoring the conservation laws that make accumulation
possible. The transition from critique to construction is therefore not optional but necessary.
Once the failure is understood as physical rather than cultural, the only remaining work is
schematic.
12

What follows is not a vision but a set of tests. For each proposed system, the question
is simple: where does it leak? Only architectures that survive this interrogation are capable
of resisting the entropy spiral. All others will converge, regardless of intent, toward noise.
18
A Formal Model of Skill Transfer Under Constraint
To move beyond abstraction, we now consider a concrete design problem: the construction
of a skill-transfer system in which the cost of simulating competence exceeds the cost of
acquiring it. This problem is representative, as it concentrates many of the leakage modes
previously identiﬁed: eﬀort laundering, failure erasure, metric detachment, and symbolic
substitution.
We begin by deﬁning skill not as declarative knowledge, but as the stable ability to
produce outcomes under varying conditions. Let a skill domain be represented by a space of
tasks T , each task t ∈T mapping an agent state s to an observable outcome o. Competence
is not the memorization of mappings, but the robustness of performance across perturbations
in t.
Formally, let an agent a have an internal policy πa such that:
o = πa(t, ϵ),
(9)
where ϵ represents noise, uncertainty, or environmental variation. A competent agent is one
for whom outcome quality Q(o) remains above threshold θ for a wide class of ϵ.
Traditional instructional systems attempt to transmit π symbolically, through explana-
tion or demonstration. This approach fails because π is not explicitly representable; it is a
product of iterative error correction embedded in sensorimotor loops. The design objective
is therefore not transmission, but conditioning.
19
The Failure of Feed-Based Instruction
Most contemporary digital learning environments are feed-based. They present a sequence
of content units ordered by engagement metrics. Progress is measured by exposure, not
outcome. From the systems perspective, a learner who watches a tutorial and a learner who
masters a task are indistinguishable, as both generate comparable engagement signals.
Let E denote exposure events and R denote real task outcomes. In feed-based systems,
13

advancement is conditioned on E, while R is unobserved:
progress ∝
X
Ei.
(10)
This structure creates a fatal ambiguity. Because R is unmeasured, there is no penalty for
non-learning. Agents are rewarded for remaining in the instructional loop rather than exiting
it through mastery. Optimization thus favors perpetual consumption over skill acquisition.
Moreover, feed-based instruction is trivially gameable. Automated agents can simulate
exposure at scale, generating the same advancement signals as human learners. The system
therefore cannot distinguish between learning, imitation, and fabrication.
20
Log-Based Skill Progression
A counterfactual design replaces feeds with logs. Instead of recording exposure, the system
records attempts, outcomes, and elapsed time. Logs are append-only and irreversible. Each
learners trajectory is a sequence of timestamped events:
La = {(t1, o1), (t2, o2), . . . , (tn, on)}.
(11)
Progression is conditioned not on the number of entries in La, but on demonstrated
outcomes. Advancement to higher task complexity requires satisfying explicit performance
constraints over a window of attempts. Failure remains visible as part of the log, providing
both the learner and the system with negative information.
This structure enforces eﬀort conservation. Each log entry corresponds to a real attempt
that consumes time and cognitive energy. Automated fabrication becomes diﬃcult because
producing plausible logs requires reproducing the distribution of errors and improvements
characteristic of genuine learning. The cost of simulating such trajectories approaches the
cost of acquiring the skill itself.
21
Adversarial Analysis: Why Simulation Fails
We now consider whether an agent could simulate competence under this regime more
cheaply than acquiring it. Suppose an adversary attempts to fabricate a log ˜L consistent
with a competent learner. To succeed, ˜L must satisfy several constraints:
First, temporal coherence: timestamps must reﬂect realistic intervals between attempts,
respecting circadian and fatigue limits. Second, error structure: early attempts must ex-
14

hibit characteristic failure modes, followed by gradual improvement. Third, variance under
perturbation: performance must remain stable across task variants.
Producing such a log requires a generative model of the learning process itself. Con-
structing this model is equivalent to solving the skill acquisition problem. Any shortcut that
reduces fabrication cost introduces statistical anomalies detectable by audit.
Thus, under log-based progression, the inequality reverses:
Csimulate ≥Clearn.
(12)
This is the desired regime. Optimization now favors participation.
22
Thermodynamic Cost of Learning
Learning consumes entropy. Each failed attempt reduces uncertainty about the task space, at
the cost of cognitive and temporal energy. The log records this entropy reduction explicitly.
By contrast, exposure-only systems externalize entropy production to the learner without
recording it.
In the proposed design, the system absorbs part of this cost by storing detailed histories.
Storage is cheap relative to human attention. The tradeoﬀis intentional: memory is used to
conserve meaning.
23
Implications for Credentialing
Credentials in this system are not symbols but summaries of logs. A credential corresponds
to a compression of La that preserves suﬃcient statistics for competence.
Because the
underlying log remains auditable, credentials cannot be divorced from history.
This eliminates credential inﬂation.
Issuing a credential carries responsibility, as its
validity can be challenged by inspecting the underlying record. Trust is restored not by
authority but by traceability.
24
Generalization Beyond Skills
While developed in the context of skill transfer, the log-based approach generalizes to other
domains: content creation, research, governance, and production. Any domain in which
outcomes can be partially observed admits a similar structure. The common requirement is
that actions leave traces that cannot be cheaply forged.
15

25
Designing Against Laziness, Not Against People
The systems proposed here are not designed to enforce virtue. They are designed to make
laziness expensive in the precise technical sense: to raise the marginal cost of simulation above
that of participation. When this condition holds, good behavior emerges as an equilibrium.
This design philosophy rejects persuasion and embraces constraint. It treats humans not
as moral agents to be corrected, but as optimizers embedded in environments. Change the
environment, and behavior follows.
26
Case Study: Factories, Logs, and the Irreducibility
of Material Work
To further ground the invariant framework, we now examine a domain in which identity,
eﬀort, and ground truth have never been optional: industrial production. Factories pro-
vide a natural counterexample to laundering environments because they operate under hard
physical constraints. Energy must be supplied, materials must be transformed, and failures
propagate immediately into measurable losses. For this reason, factories have historically
evolved architectures that conserve eﬀort, expose failure, and anchor symbolic representa-
tions to material reality.
This case study is not oﬀered as an ideal to be romanticized, but as an existence proof.
It demonstrates that systems resistant to entropy do not rely on persuasion or moral com-
pliance. They rely on accounting.
27
Material Flow as an Identity Anchor
In an industrial setting, identity is not primarily attached to persons, but to processes. A
production line is identiﬁed by its conﬁguration, its throughput, and its historical perfor-
mance. These properties persist across personnel changes. Crucially, they cannot be reset
without incurring cost.
Let a factory be modeled as a directed graph G = (V, E), where vertices represent
transformation stages and edges represent material ﬂow. Each edge carries quantities of
matter and energy, and each vertex imposes constraints deﬁned by physics and chemistry.
The state of the factory at time t is a vector S(t) encoding inventories, machine states, and
environmental conditions.
Any claim about factory performance—output rate, yield, eﬃciency—must correspond
16

to a physically consistent trajectory of S(t). Unlike digital metrics, these claims are not
free-ﬂoating. They are anchored by conservation laws:
X
inputs
mi =
X
outputs
mo +
X
losses
ml,
(13)
and similarly for energy.
Because these constraints are enforced by nature, simulation without participation is
impossible.
A fabricated report cannot cause products to exist.
Identity laundering is
therefore structurally excluded. The process has memory, and that memory is written into
matter.
28
Logs Versus Dashboards
Modern factories employ dashboards to summarize system state. However, dashboards are
not authoritative. They are projections derived from logs and sensors. When discrepancies
arise, the dashboard yields to the log, and the log yields to the physical measurement.
This hierarchy is essential. Dashboards are reports; logs are histories; sensors provide
ground truth. Any inversion of this hierarchy produces catastrophic failure. If a dashboard
is allowed to override sensor readings, the system enters a hallucination regime, continuing
operation based on false premises.
Formally, let D(t) denote dashboard state, L(t) denote logs, and P(t) denote physical
measurements. Valid operation requires:
D(t) = f(L(t)),
L(t) = g(P(t)),
(14)
with no feedback from D to P.
When this ordering is violated, symbolic optimization
overwhelms reality.
The relevance to digital platforms is direct. Social systems that privilege dashboards
(engagement metrics) over logs (historical action records) and lack any anchoring to physical
measurement inevitably drift into self-referential optimization.
29
Failure Visibility and Root Cause Analysis
Factories do not suppress failure. They institutionalize it. When a defect occurs, it triggers
inspection, root cause analysis, and corrective action. These processes are costly, but their
cost is justiﬁed by the avoidance of recurrence.
17

This practice exempliﬁes the invariant of failure visibility. Defects are not erased; they
are studied. The resulting knowledge accumulates, improving system performance over time.
This accumulation is impossible in laundering environments, where failures leave no durable
trace.
Let Fi denote a failure event, and let C(Fi) denote the corrective knowledge extracted.
In a learning system:
X
i
C(Fi) > 0,
(15)
and contributes to future robustness. In a laundering system, C(Fi) = 0 because failures are
forgotten. Optimization therefore repeats the same errors indeﬁnitely.
30
Throughput Limits and Throttling
Factories operate under explicit throughput limits determined by machine capacity, heat
dissipation, and human factors. When these limits are exceeded, quality degrades or the
system fails. Throttling is not optional; it is required for survival.
Digital platforms, by contrast, treat throughput as unbounded. Content production is
allowed to scale independently of processing capacity or human attention. The result is
chronic overload.
In a physically grounded system, throttling restores stability. When defect rates rise,
production slows. Analogously, a digital system that models attention thermodynamically
must reduce output when entropy exceeds acceptable bounds. This is not censorship; it is
load management.
31
Implications for Platform Design
The factory case demonstrates that resistance to entropy is achievable when invariants are
enforced at the substrate level. Identity is conserved because processes persist. Eﬀort is
conserved because material transformation requires energy. Failure is visible because defects
propagate. Ground truth is non-negotiable because physics enforces it.
A digital platform that aspires to similar stability must replicate these properties ab-
stractly. It must privilege logs over feeds, outcomes over exposure, and physical or cryp-
tographic anchors over symbolic claims. It must accept reduced liquidity in exchange for
accumulated meaning.
18

32
Toward a Minimal Platform Speciﬁcation
We now sketch, at a high level, a minimal social platform architecture consistent with the
invariant framework. The goal is not maximal engagement, but maximal resistance to laun-
dering.
The platform is log-native. All actions append to an immutable history. Feeds, if present,
are views over logs rather than primary data structures. Identity is bound to history, and
re-entry after abandonment incurs cost proportional to lost state.
Metrics are derived, not targeted. They summarize historical performance but do not
gate visibility directly. Visibility emerges from trust, which emerges from traceability.
Automation is permitted only where it cannot fabricate logs. Generative tools may assist
composition, but submission requires interaction with constraints that cannot be bypassed
algorithmically.
33
Why This Is Hard
Such a platform will not dominate existing ecosystems. It sacriﬁces growth, liquidity, and
ease of use. It demands patience, tolerance for failure, and sustained eﬀort. These require-
ments are precisely why it can conserve meaning.
The prevailing digital economy optimizes for the speed of symbols because symbols are
cheap. Conserving objects—whether physical products or durable skills—is expensive. But
expense is not a defect; it is the mechanism by which entropy is held at bay.
The task ahead is not to convince users to want such systems, but to build them so
that, once entered, they function correctly.
As in factories, the system must work even
when participants are tired, distracted, or self-interested. Only constraint can provide that
guarantee.
34
Dark Patterns, Advertising, and the Economics of
False Promise
The preceding analysis has deliberately avoided attributing the collapse of digital meaning to
individual malice. However, this restraint must not be mistaken for neutrality with respect
to incentive design.
Certain architectural choices are not merely negligent but actively
extractive. Chief among these are advertising-driven dark patterns and subscription-based
monetization schemes that exploit informational asymmetry and human hope rather than
19

productive capacity.
Advertising, in its contemporary digital form, is not a neutral funding mechanism. It
is an optimization regime. Its objective is not to align users with valuable outcomes, but
to maximize conversion under conditions of uncertainty. This distinction is critical. Where
value creation requires time, skill, and external constraint, advertising rewards persuasion
independent of deliverable performance. As a result, advertising systems exert consistent
pressure toward misrepresentation, exaggeration, and the sale of non-guarantees.
35
Dark Patterns, Advertising, and the Economics of
False Promise
The preceding analysis has deliberately avoided attributing the collapse of digital meaning to
individual malice. However, this restraint must not be mistaken for neutrality with respect
to incentive design.
Certain architectural choices are not merely negligent but actively
extractive. Chief among these are advertising-driven dark patterns and subscription-based
monetization schemes that exploit informational asymmetry and human hope rather than
productive capacity.
Advertising, in its contemporary digital form, is not a neutral funding mechanism. It
is an optimization regime. Its objective is not to align users with valuable outcomes, but
to maximize conversion under conditions of uncertainty. This distinction is critical. Where
value creation requires time, skill, and external constraint, advertising rewards persuasion
independent of deliverable performance. As a result, advertising systems exert consistent
pressure toward misrepresentation, exaggeration, and the sale of non-guarantees.
36
User Capability Suppression
A less obvious but equally consequential class of dark patterns operates through the suppres-
sion of general-purpose capability rather than through overt manipulation. In such cases,
users are not misled about prices or terms, but are systematically prevented from exercising
forms of control that would reduce dependency on proprietary interfaces.
The omission of mature, widely understood tools in favor of constrained substitutes func-
tions as a form of architectural disempowerment. A canonical example is the near-universal
absence of full-featured, modal text editors in contemporary mobile operating systems. Ed-
itors with decades of stable semantics, composability, and scriptability are replaced by sim-
pliﬁed interfaces that omit even elementary operations such as global search and replace.
20

These omissions are not plausibly attributable to technical limitation. Such tools have
existed for decades, require minimal resources, and in many cases are already present in-
directly within the operating systems own build and maintenance toolchain. The eﬀect of
this suppression is not merely inconvenience. Text editing is a foundational capability that
underlies programming, conﬁguration, automation, and repair.
By restricting access to general-purpose editors and requiring users to install emulation
layers or sandboxed environments to recover basic functionality, platforms increase friction
for exploratory, infrastructural, and non-consumptive use. At the same time, they promote
narrowly scoped applications optimized for content consumption, subscription retention, or
advertising integration.
This pattern aligns with the broader incentive structure analyzed here. General-purpose
tools reduce mediation by allowing users to act directly on underlying representations. Con-
strained interfaces increase mediation by forcing interaction through predeﬁned workﬂows
that are easier to monetize, instrument, and surveil. The systematic removal of mature tools
is therefore not accidental.
It is an equilibrium outcome in systems that reward controllable engagement over user
autonomy. From an architectural perspective, capability suppression functions as a dark
pattern because it raises the cost of self-directed work while lowering the cost of passive
interaction. It does not deceive users about what is possible; it quietly narrows the space
of what is allowed. In doing so, it contributes to the same entropy-increasing dynamics as
more explicit forms of persuasion: dependence replaces competence, and optimization shifts
from problem-solving to interface navigation.
37
Hope as an Extractable Resource
A deﬁning feature of productivity marketing, inﬂuencer coaching, and income-subscription
schemes is their reliance on hope rather than contractible outcomes. Hope, unlike labor or
capital, is non-rival and unmetered. It can be consumed repeatedly without depletion at the
system level, even as it is depleted at the individual level. This makes it an ideal target for
extraction.
The economic structure of these oﬀerings reveals their ﬂaw. If a plan, method, or system
were reliably capable of generating surplus value, the rational course of action would be
to internalize it.
Firms do not sell proprietary arbitrage strategies; they exploit them.
Engineers are not charged to deploy guaranteed optimizations; they are hired to implement
them.
Any oﬀer that inverts this relationship—requiring the buyer to pay for access to
supposed proﬁt—is prima facie suspect.
21

Formally, let V denote the expected value generated by a proposed method, and let C
denote its implementation cost. In a genuine opportunity, the provider captures value by
deploying the method themselves:
V −C > 0
⇒
internal exploitation.
(16)
In a marketing-driven scheme, revenue is instead extracted by selling access:
R =
X
i
f(beliefi),
(17)
where R depends on persuasion rather than performance. The system thus selects for belief
manipulation over outcome realization.
38
Subscription Models and the Illusion of Progress
Subscription-based productivity tools and coaching platforms intensify this misalignment.
Revenue accrues through continued participation, not successful exit. The optimal customer,
from the platforms perspective, is not one who achieves mastery and leaves, but one who
remains indeﬁnitely engaged while failing to reach closure.
This creates a structural conﬂict of interest. Let T denote the time required for genuine
skill acquisition, and let τ denote the average subscription duration. If τ < T, the system
cannot deliver competence before churn. If τ > T, the system loses revenue when users
succeed. In both cases, the platform is incentivized to substitute symbolic progress for real
outcomes.
Dashboards, streaks, gamiﬁed metrics, and motivational notiﬁcations function as dark
patterns precisely because they mimic the feedback signals of genuine learning without
enforcing the underlying constraints. They provide the sensation of motion without dis-
placement. From the users perspective, eﬀort appears to be expended; from the systems
perspective, no veriﬁable work is required.
39
Dark Patterns as Entropy Injection
Dark patterns are often framed as manipulative interface tricks. This framing understates
their role. They are entropy injection mechanisms. By encouraging rapid decisions, obscuring
costs, and exploiting cognitive biases, dark patterns accelerate churn and suppress reﬂection.
They increase throughput at the expense of coherence.
22

Examples include default opt-ins, obscured cancellation paths, artiﬁcial scarcity cues, and
algorithmic ampliﬁcation of emotionally charged content. Each of these patterns reduces
the informational content of user actions.
Decisions become less diagnostic of intent or
understanding and more reﬂective of momentary arousal.
In information-theoretic terms, dark patterns increase the conditional entropy of actions
given preferences:
H(A | P) ↑,
(18)
where A denotes observed actions and P denotes underlying goals. As this entropy increases,
the systems ability to align behavior with durable outcomes collapses.
40
Advertising as Anti-Learning Infrastructure
The interaction between advertising and null pedagogy is not incidental. Advertising-funded
platforms beneﬁt when users remain uncertain, aspirational, and incomplete. A user who
acquires durable competence reduces their susceptibility to persuasion. Conversely, a user
perpetually in search of optimization remains a reliable source of revenue.
This dynamic explains the proliferation of content that teaches how to gain followers,
optimize reach, or monetize engagement without producing anything of independent value.
Such content does not compete with advertising; it complements it. Both rely on the same
illusion: that success can be obtained through symbolic manipulation rather than material
or cognitive investment.
The system therefore teaches not merely non-learning, but mislearning. Users internalize
the belief that outcomes follow from visibility rather than causation, and that persuasion
is a substitute for competence. This belief persists even when repeatedly falsiﬁed, because
falsiﬁcation carries no structural consequence. The subscription renews; the feed refreshes;
the identity resets.
41
Perverse Incentives and the Sale of Certainty
The most corrosive feature of these architectures is their implicit claim of certainty. Pro-
ductivity schemes, monetization courses, and optimization plans are marketed as reliable
pathways despite the absence of enforceable guarantees. The legal and technical framing
avoids explicit promises, substituting implication and testimonial for contract.
This asymmetry is decisive. Providers are insulated from downside risk, while consumers
absorb failure. In a conserved system, risk is borne by those who claim expertise. In a
23

laundering system, risk is externalized to the hopeful.
Any architecture that permits the sale of non-guaranteed outcomes without attaching
liability is structurally dishonest, regardless of intent. It rewards those who can simulate
conﬁdence most eﬀectively, not those who can deliver results.
42
Advertising as Structural Corruption
Advertising, dark patterns, and subscription traps are not peripheral irritations layered atop
an otherwise functional system. They are the operational logic of an architecture that has
abandoned conservation. They monetize uncertainty, exploit hope, and convert attention
into revenue without producing commensurate work.
In such an environment, dishonesty is not an ethical failure; it is a competitive advantage.
Any attempt to restore meaning must therefore confront advertising not as content, but as
infrastructure. As long as persuasion is decoupled from deliverable outcomes, optimization
will select for those most willing to exploit belief.
The implication is stark. A system that wishes to conserve meaning must either abolish
advertising as a funding mechanism or bind it to enforceable guarantees rooted in external
reality. There is no third option. Where persuasion is proﬁtable without accountability,
entropy will prevail.
43
Paying for Compression:
Information Gain as a
Funding Primitive
The critique of advertising and subscription-based monetization leads naturally to a design
question: if persuasion-driven revenue corrupts epistemic systems, what alternative funding
mechanism can align incentives with genuine contribution? Any viable replacement must
satisfy two conditions.
First, it must reward work that reduces uncertainty rather than
exploits it. Second, it must be resistant to symbolic gaming, fabrication, and scale-driven
noise. One promising direction is to ground compensation in compressibility: the degree to
which a contribution reduces the description length of a systems state.
Compression is not metaphorical here. In information theory, compressibility is a pre-
cise measure of structure. A dataset that admits a shorter description contains regularities
that can be exploited for prediction, control, or understanding. Contributions that increase
compressibility are therefore contributions that add structure. Unlike engagement metrics,
24

compressibility is not easily inﬂated by repetition or arousal. Noise is, by deﬁnition, incom-
pressible.
Let a corpus D have Kolmogorov complexity K(D), deﬁned as the length of the shortest
program that produces D. While K is not computable in general, practical approximations
via compression algorithms or model description length are suﬃcient for incentive alignment.
A contribution ∆D is valuable if:
K(D ∪∆D) < K(D) + K(∆D),
(19)
that is, if the joint description is shorter than the sum of parts. This inequality formalizes
synergy. The contribution reveals structure that makes the whole easier to describe.
A system that rewards such contributions pays not for attention captured, but for entropy
reduced.
44
From Engagement to Description Length
Current platforms reward content proportional to the number of independent impressions it
generates. This implicitly treats each impression as informationally independent, ignoring
redundancy.
Viral junk thrives precisely because redundancy is proﬁtable.
A thousand
copies of the same pattern generate a thousand monetizable events.
A compressibility-based system inverts this logic. Redundant contributions rapidly lose
marginal value. Once a pattern is known, repeating it adds nothing. Only contributions
that introduce new regularities or resolve uncertainty are rewarded.
Let M be a predictive model trained on corpus D. The value of a contribution ∆D can
be measured as the reduction in model loss or description length:
∆V = L(M, D) −L(M ′, D ∪∆D),
(20)
where M ′ is the updated model. Contributors are compensated in proportion to ∆V .
This mechanism naturally discourages spam, imitation, and synthetic ﬁller. Such con-
tent does not improve compression; it degrades it.
The system therefore throttles noise
automatically, without moderation.
25

45
Scientiﬁc Problems as Anchors
To prevent the collapse into self-referential optimization, compressibility must be anchored to
external problems. Purely internal compression risks rewarding artifacts that exploit quirks
of the model rather than structure in the world. The solution is to tie rewards to well-deﬁned
scientiﬁc or engineering tasks whose outcomes are independently veriﬁable.
Examples include predictive accuracy on physical systems, improved material simula-
tions, optimized logistics routes, or veriﬁed reductions in energy consumption. Each task
deﬁnes a loss function grounded in external reality. Contributions that improve performance
against this function are rewarded; those that do not are ignored.
This transforms the platform into a distributed research and engineering substrate. Par-
ticipants are not paid for posting, but for moving the frontier of solvable problems. Hope
is replaced by contractible contribution. The system does not promise income; it pays for
measurable progress.
46
Storage as a Market for Structure
The proposal may be reframed as a storage system that pays users to make stored data
more compressible. Storage costs scale with entropy. Data that is structured, redundant, or
explanatory is cheaper to store and more useful to retrieve. Paying contributors to reduce
entropy aligns storage economics with epistemic value.
Let S(D) denote the storage cost of corpus D, approximated by compressed size. A
contribution ∆D that reduces S(D) produces a direct economic beneﬁt:
∆S = S(D) −S(D ∪∆D) > 0.
(21)
The system can share this beneﬁt with contributors. Unlike advertising, this revenue
is not extracted from belief or attention, but from real savings. The incentive loop closes
cleanly: structure reduces cost; reduced cost funds contributors.
Crucially, this mechanism is anti-viral. High-entropy content increases storage cost and
is therefore penalized. The system selects for clarity, abstraction, and synthesis.
47
Resistance to Gaming
Any incentive system invites adversarial behavior. A compressibility-based market resists
common attacks precisely because compression is diﬃcult to fake. Generating data that
26

appears structured but does not improve real predictive models is possible only if the model
is poorly speciﬁed. Anchoring to external tasks mitigates this risk.
Moreover, fabrication at scale increases entropy. Synthetic noise is expensive to compress.
Attempting to game the system by ﬂooding it with generated content raises costs rather than
revenue. The optimal strategy remains contribution, not simulation.
Identity continuity further strengthens resistance. Because rewards depend on long-term
impact on shared models, abandoning identity forfeits accrued credit. Namespace laundering
becomes costly.
48
Pedagogical Consequences
Such a system teaches implicitly. Contributors learn by attempting to reduce uncertainty in
well-deﬁned domains. Failure is visible as lack of compression gain. Progress is cumulative
and transferable. Skills acquired generalize beyond the platform because they are grounded
in real problems.
Unlike tutorial economies, there is no incentive to promise mastery. The system makes
no claims about outcomes. It simply pays for measurable contribution. Those who learn
eﬀectively earn more; those who do not are neither exploited nor encouraged to persist under
false pretenses.
49
Funding Truth Without Selling Hope
A compressibility-based incentive system replaces persuasion with accounting. It does not
ask users to believe in a plan; it asks them to contribute structure.
It does not mone-
tize aspiration; it monetizes entropy reduction. This shift addresses the core pathology of
advertising-driven platforms: the extraction of hope without obligation.
By tying compensation to information gain anchored in external reality, such a system
restores the link between eﬀort and reward. It renders dark patterns unproﬁtable and null
pedagogy irrelevant. Most importantly, it makes lying expensive and learning valuable.
This does not guarantee justice or success. It guarantees only that rewards correspond
to work performed. In a landscape saturated with promises, that constraint alone would
constitute a radical improvement.
27

50
Simulation as a Constraint Medium: 4X-Style Worlds
and Long-Horizon Selection
The proposal to embed contribution and learning within large-scale simulation environments
marks a further reﬁnement of the invariant-based approach. Rather than rewarding isolated
artifacts or short-horizon optimizations, such environments shift the unit of evaluation to
long-term, path-dependent outcomes. In doing so, they reintroduce temporal scale, irre-
versibility, and compounding consequences—features that are largely absent from contem-
porary digital platforms but are essential to meaningful learning and civilizational reasoning.
Strategy simulations of the so-called 4X class—explore, expand, exploit, exterminate—
are instructive not because of their entertainment value, but because they model complex
systems evolving over extended time horizons. When properly designed, these simulations
function as constrained sandboxes in which choices propagate forward, interact nonlinearly,
and impose opportunity costs. A decision made early cannot be trivially undone; it alters
the state space available to all subsequent decisions.
In the context envisioned here, the simulation is not a game in the conventional sense. It
is a synthetic laboratory for studying coupled ecological, biological, chemical, and logistical
systems under realistic constraints. The role of participants is not to maximize a score, but
to propose interventions—terraforming strategies, infrastructure layouts, energy systems,
governance mechanisms—whose eﬀects unfold over simulated centuries.
51
Long-Horizon Credit Assignment
A central diﬃculty in rewarding real-world contribution is credit assignment across time.
Short-horizon metrics favor immediate gains, while long-horizon beneﬁts are diﬀuse and
diﬃcult to attribute. Simulation environments partially resolve this problem by compressing
time while preserving causality. Hundreds of years of ecological or infrastructural evolution
can be simulated in hours or days, allowing the consequences of design choices to become
observable within a tractable window.
Formally, let a simulation state S(t) evolve according to dynamics:
S(t + 1) = F(S(t), at, ηt),
(22)
where at denotes participant actions and ηt represents stochastic variation. The value of
an action is not its immediate eﬀect on S(t + 1), but its contribution to long-term system
viability, resilience, or productivity over a horizon T.
28

Reward functions in such a system are necessarily delayed and aggregated. Compensation
is tied to the integral of system performance metrics:
V (a0:T) =
Z T
0
U(S(t)) dt,
(23)
where U encodes externally grounded objectives such as biomass stability, energy eﬃciency,
or material throughput.
This structure strongly disincentivizes superﬁcial optimization.
Short-term exploitation that degrades long-term capacity yields negative value.
52
Simulation as Anti-Laundering Infrastructure
Crucially, simulation-based contribution resists the laundering pathologies described earlier.
Producing a convincing proposal in such an environment requires engaging with the un-
derlying models. Biological growth rates, chemical equilibria, thermodynamic limits, and
logistical constraints must all be respected. Fabrication without understanding quickly leads
to catastrophic outcomes visible in the simulated future.
The use of computational assistance does not undermine this structure. Whether partic-
ipants calculate by hand or with software is irrelevant; what matters is that the simulation
enforces invariants. Assistance tools merely change the eﬃciency with which hypotheses are
explored. They do not eliminate the need to satisfy constraints. As task diﬃculty scales,
assistance becomes a necessity rather than a shortcut.
This property is decisive. Unlike content platforms where automation enables scale with-
out competence, simulation environments absorb automation by increasing problem dimen-
sionality.
The ceiling rises as tools improve.
Optimization pressure therefore selects for
deeper understanding rather than faster imitation.
53
Ecosystems, Terraforming, and Megastructures
Terraforming scenarios provide a particularly rich testbed. They couple planetary physics,
atmospheric chemistry, microbial ecology, and energy economics into a single evolving sys-
tem. Decisions about albedo modiﬁcation, greenhouse gas introduction, ocean chemistry, or
orbital infrastructure interact over centuries. Mistakes are not localized; they cascade.
Participants proposing megastructures—solar arrays, orbital mirrors, carbon sequestra-
tion systems, biosphere scaﬀolds—must account for material sourcing, construction timelines,
maintenance burdens, and failure modes. The simulation enforces conservation of mass and
energy. Ambitious schemes that neglect logistics collapse under their own weight.
29

In this setting, success is not deﬁned by spectacle but by stability. The highest-value
contributions are those that achieve slow, robust improvements without inducing runaway
dynamics.
Compression emerges naturally: good designs simplify the systems behavior,
reducing volatility and uncertainty.
54
Collective Exploration Without Monetized Hope
Because rewards are tied to simulation outcomes rather than promises, the system avoids
exploiting hope. There is no claim that participation will yield wealth. Compensation reﬂects
measurable contribution to shared understanding. Some participants will earn more than
others; many will earn nothing. This is not framed as failure, but as feedback.
Importantly, the simulation environment can host multiple, parallel worlds. Competing
hypotheses are explored independently. There is no single canonical solution. This plurality
prevents premature convergence and encourages epistemic humility. Models are updated as
discrepancies between prediction and outcome are observed.
55
From Simulation to Reality
The ultimate value of such simulations lies in their transferability. Designs that perform well
across varied scenarios and perturbations are candidates for real-world experimentation.
Because the simulation preserves logs of all decisions and outcomes, successful strategies are
traceable and auditable. Learning accumulates.
This pipeline—from simulation to pilot project to deployment—restores a disciplined
interface between imagination and reality. Unlike advertising-driven innovation narratives,
it does not skip validation. Each stage imposes additional constraints, ﬁltering out fragile
ideas.
56
Diﬃculty as a Feature
Simulation-based contribution systems embrace diﬃculty rather than concealing it. They
make clear that meaningful progress in complex domains requires sustained engagement with
constraint-laden models. They do not promise success; they oﬀer a medium in which success,
when it occurs, is legible and earned.
By embedding incentives in long-horizon, physically grounded simulations, such systems
align learning, contribution, and reward without resorting to persuasion or spectacle. They
30

transform play into practice and imagination into accountable design. In doing so, they point
toward a digital architecture capable of conserving meaning even under intense optimization
pressure.
57
Interfaces, Borders, and the Cost of Artiﬁcial Me-
diation
The ﬁnal extension of the argument concerns mediation itself. Screens, interfaces, borders,
and bureaucratic abstractions are often treated as permanent features of civilization. In
reality, they are compensatory structures: temporary prostheses erected to manage trust
failures, coordination limits, and unresolved conﬂict between heterogeneous agents. When
these structures persist beyond their necessity, they cease to be stabilizing and become
sources of waste, hostility, and entropy.
Digital interfaces, in particular, should be understood not as neutral tools but as scaf-
folding. They exist because direct coordination, mutual intelligibility, and trust are costly or
unavailable. A screen stands in for a relationship; a dashboard stands in for understanding;
a metric stands in for judgment. These substitutions are initially useful, but they carry
a hidden cost: they ﬂatten nuance, suppress context, and invite optimization against the
proxy rather than the underlying reality.
The long-term objective of a meaning-conserving architecture is therefore not to perfect
interfaces, but to render them obsolete wherever possible. As trust, traceability, and shared
constraint increase, the need for heavy mediation diminishes. Interfaces should thin over
time, not thicken.
58
Screens as Trust Prostheses
Screens mediate interaction by reducing it to symbolic exchange. This reduction is necessary
when agents lack shared history, shared language, or shared incentives. However, it also
eliminates embodied cues, tacit knowledge, and the friction that naturally regulates behavior
in physical interaction.
In laundering environments, screens become the primary site of optimization. Actors
learn to perform for the interface rather than for each other. This leads to performative
ﬂuency divorced from competence. The interface becomes a stage, and reality recedes.
In contrast, systems grounded in logs, outcomes, and shared simulations reduce the need
for performative display. Trust is established through traceable contribution rather than
31

presentation.
As a result, interfaces can be simpliﬁed.
Information ﬂows directly from
activity to record, bypassing theatrical mediation.
59
Borders as Coordination Failures
Borders function analogously at the geopolitical scale.
They are not intrinsic to human
diversity but responses to coordination breakdowns among groups with diﬀering languages,
religions, strategies, and historical grievances. Where mutual intelligibility and trust are
low, separation reduces conﬂict. However, separation also ossiﬁes diﬀerence and ampliﬁes
scarcity.
Artiﬁcial scarcity arises when resources, opportunities, and labor are constrained by
political boundaries rather than physical necessity. Energy consumption provides a clear
example. Enormous amounts of energy are expended to heat cold regions and cool hot ones,
even as other regions naturally provide these conditions. This ineﬃciency is not mandated
by physics but by coordination failure.
If agents could migrate freely in response to climatic conditions and resource availability,
energy expenditure would decrease dramatically. Heating and cooling would be replaced,
in part, by relocation.
Borders prevent this adaptation, forcing societies to compensate
technologically for what could be solved logistically.
60
Artiﬁcial Scarcity and Hostility
Scarcity, when artiﬁcially induced, intensiﬁes hostility.
Groups compete for constrained
resources not because those resources are inherently limited, but because access is restricted.
This dynamic fuels zero-sum thinking and legitimizes defensive aggression.
Advertising-driven systems exacerbate this problem by manufacturing perceived scarcity—
limited-time oﬀers, exclusive access, status competition—within already constrained envi-
ronments. The result is a continuous state of low-grade conﬂict, both psychological and
material.
A meaning-conserving architecture seeks to reduce artiﬁcial scarcity by increasing trans-
parency, mobility, and shared infrastructure. When access to resources and opportunities is
governed by contribution and need rather than identity or location, competition gives way
to coordination.
32

61
Mobility as an Energy Optimization Strategy
The historical assumption that populations must remain ﬁxed while energy is transported is
increasingly untenable. Advances in communication technology—ﬁber optics, satellite net-
works, distributed computation—have already decoupled many forms of work from location.
Yet social and institutional inertia preserves commuting patterns that waste time, energy,
and attention.
Commuting is a paradigmatic example of entropy production. It converts human time
and metabolic energy into waste heat without producing commensurate informational or
material value. Where remote coordination is possible, compulsory commuting represents a
failure to adapt to available constraints.
A system that optimizes for conserved meaning would treat mobility as a ﬁrst-class
variable. People would be encouraged to relocate toward climates and infrastructures that
minimize energy expenditure and maximize well-being. Work would follow capability, not
location. Physical presence would be reserved for tasks that genuinely require it.
62
Diversity Without Fragmentation
The elimination of unnecessary mediation does not imply homogenization.
Diversity of
language, culture, and strategy is essential for resilience. The problem is not diﬀerence, but
enforced separation under conditions of artiﬁcial scarcity.
Shared simulation environments and log-based coordination systems oﬀer a way to pre-
serve diversity while reducing hostility. Participants engage with common constraints even as
they bring distinct perspectives. Disagreement becomes productive rather than adversarial
because it is adjudicated by outcomes rather than identity.
In such a system, borders soften into gradients. Interfaces recede into background infras-
tructure. Trust accrues through shared work rather than symbolic allegiance.
63
Toward a Low-Mediation Civilization
Screens, borders, and interfaces are not ends in themselves. They are temporary solutions
to coordination problems. As systems evolve to conserve identity, eﬀort, and meaning, the
need for these prostheses diminishes.
The ultimate goal is not a hyper-mediated digital civilization, but a low-mediation one: a
society in which trust is established through traceable contribution, where mobility replaces
33

coercion, and where energy is conserved by aligning human activity with physical reality
rather than compensating for institutional rigidity.
Such a civilization does not eliminate conﬂict or diﬀerence. It eliminates unnecessary
waste. It replaces persuasion with accounting, hostility with coordination, and spectacle
with structure. The path to this outcome lies not in better interfaces, but in architectures
that make interfaces optional.
64
The Calculus of Coordination:
Energy, Mobility,
and Trust
The preceding sections have traced a continuous line from information-theoretic failure to
logistical ineﬃciency.
What remains is to unify these observations into a single formal
framework capable of explaining why modern systems expend extraordinary energy merely
to remain coherent. This framework treats coordination itself as a thermodynamic problem
and mediation as a compensatory cost imposed by trust failure.
In any system of heterogeneous agents distributed across space, the total energetic burden
may be decomposed as:
Etotal = Eproduction + Etransport + Emediation.
(24)
Here, Eproduction denotes the energy required to generate goods, services, or knowledge;
Etransport denotes the energy required to move people, materials, or signals; and Emediation
denotes the energy required to coordinate action in the presence of mistrust, misalignment,
or informational opacity.
In a well-designed system, mediation costs are subdominant. Coordination is achieved
largely through shared constraints, local trust, and traceable contribution. In the contempo-
rary static-interface regime, however, Emediation grows superlinearly as other forms of adap-
tation are suppressed.
Borders, bureaucracies, compliance regimes, surveillance systems,
dashboards, and screens proliferate not because they are intrinsically valuable, but because
they substitute for mobility, intelligibility, and trust.
64.1
The Thermodynamic Cost of the Static State
The nation-state presupposes low agent mobility. Populations are treated as ﬁxed, with
identities bound to territory rather than function. Let v denote average mobility velocity of
agents across climatic and economic gradients. The static-state assumption corresponds to
34

v ≈0. Under this constraint, environmental mismatch must be compensated technologically.
Consider an agent residing in a region with mean temperature Tr, while their physiological
comfort temperature is Tc. The energy required for climate compensation over a lifetime L
is:
Ecomp =
Z L
0
k|Tr(t) −Tc| dt,
(25)
where k is a proportionality constant capturing building ineﬃciency and infrastructure loss.
If the cost of relocation ∆Cmove satisﬁes:
∆Cmove < Ecomp,
(26)
then preventing relocation constitutes an energetically irrational constraint.
Borders, in this formulation, function as thermal insulators. They maintain high-potential
diﬀerences—economic, climatic, and opportunity gradients—by restricting ﬂow. As in phys-
ical systems, sustained gradients generate pressure. When the insulation fails, the resulting
ﬂow is abrupt and destabilizing, manifesting as migration crises, humanitarian emergencies,
or political shocks. These are not anomalies; they are leak events in an over-insulated system.
64.2
Mobility as Entropy Minimization
Mobility reduces entropy production by allowing agents to align with environmental gradients
rather than compensating against them. This principle is already exploited in non-human
systems. Species migrate seasonally to minimize metabolic expenditure. Supply chains re-
route dynamically to reduce cost. Only human political systems insist on static allocation
under changing conditions.
In a meaning-conserving architecture, mobility is not a threat but a control variable.
Allowing agents to relocate in response to gradients reduces both Etransport and Emediation.
Fewer resources need be moved long distances, and fewer abstractions are required to enforce
artiﬁcial allocation.
The resistance to mobility is therefore not energetic but political. It arises from identity
laundering at the geopolitical level: the substitution of symbolic allegiance for traceable
contribution.
64.3
Interfaces as Information Sinks
The same logic applies at the informational scale. Screens and interfaces arise where direct
coupling between action and outcome is weak or absent. They translate physical or social
35

processes into symbolic representations that can be manipulated without eﬀecting durable
change.
Let S denote the true state of a system and I denote the interface representation. Mu-
tual information I(S; I) measures how much the interface reveals about reality. We deﬁne
interface opacity Ωas:
Ω= Nsymbolic actions
∆S
,
(27)
where ∆S is the net state change induced by those actions. In a low-mediation system,
Ω≈1; each action eﬀects a real change. In a high-mediation system, Ω→∞; symbolic
activity proliferates while state remains unchanged.
Advertising-driven platforms maximize Ωby design. They reward symbolic manipulation—
clicks, scrolls, likes—decoupled from material consequence. As opacity increases, mutual
information collapses. Users interact increasingly with the interface rather than with the
underlying system. Trust must then be reconstituted through additional layers of medi-
ation: veriﬁcation badges, moderation, recommendation algorithms. Each layer increases
Emediation.
64.4
Symbolic Allegiance Versus Traceable Contribution
At both geopolitical and digital scales, the dominant coordination mechanism is symbolic
allegiance.
Citizenship, brand loyalty, platform aﬃliation, and professional credentialing
function as coarse proxies for trust. They are necessary only when direct evidence of contri-
bution is unavailable.
Traceable contribution oﬀers an alternative. When identity is conserved and actions leave
durable logs, trust emerges from history rather than declaration. The need for passports,
resumes, follower counts, and reputational theater diminishes.
Formally, let La denote the contribution log of agent a. Trust T(a) becomes a function
of La rather than of symbolic markers:
T(a) = f(La),
(28)
with f monotonic in demonstrated outcomes. Under this regime, belonging is inferred, not
asserted. Allegiance becomes redundant.
This shift has profound implications. Borders soften into gradients governed by contribu-
tion and need. Institutions reorganize around function rather than territory. Coordination
costs fall because veriﬁcation is local and continuous rather than centralized and episodic.
36

64.5
Work as State Update in Shared Simulations
The convergence of these ideas points toward a new commons: shared simulations that
function as coordination substrates. Rather than performing work for managers through
interfaces, agents interact with persistent models of factories, ecosystems, or research pro-
grams. The work itself is the update to the shared state.
Such simulations enforce physical and logical constraints. They reduce interface opacity
by making state changes explicit. They enable distributed coordination without requiring
high-trust relationships or heavy mediation.
Logs record all actions, preserving identity
continuity.
In this context, screens are no longer stages but windows.
They mediate only what
cannot yet be enacted directly. As trust and shared understanding increase, interfaces can
thin or disappear entirely.
64.6
The Static State as an Entropy Trap
The static state—characterized by ﬁxed populations, thick interfaces, and symbolic allegiance—
is an entropy trap. It suppresses adaptive ﬂow, forcing systems to expend increasing energy
on compensation and mediation. Borders and screens proliferate not because they work well,
but because they substitute for mobility and trust.
A meaning-conserving civilization must therefore abandon the assumption of stasis. It
must treat mobility as an energy optimization, mediation as a cost to be minimized, and
trust as an emergent property of traceable contribution. Only under these conditions can
the total energy of coordination be reduced rather than continually escalated.
This completes the transition from information theory to logistical physics. The remain-
ing task is architectural: to specify institutions, simulations, and legal frameworks that
embody these principles. The question is no longer whether the static state is ineﬃcient,
but how long it can persist before its accumulated pressure forces rupture.
65
Synthesis: Civilization as an Entropy-Minimizing
Process
The analysis undertaken in this work has progressed deliberately across scales: from indi-
vidual digital artifacts to platforms, from platforms to institutions, and from institutions to
planetary logistics. What emerges is not a collection of disconnected critiques, but a single
unifying principle. Civilization, when functioning coherently, is an entropy-minimizing pro-
37

cess. When it fails, it does not merely become unjust or ineﬃcient; it becomes energetically
wasteful, information-poor, and structurally brittle.
This framing resolves a persistent confusion in contemporary discourse. The present cri-
sis is often attributed to excessive complexity, technological acceleration, or cultural decay.
In fact, the dominant pathology is the opposite. We are expending extraordinary energy
to maintain an artiﬁcial stasis that suppresses adaptive ﬂow, destroys mutual information,
and replaces conserved structure with symbolic throughput. The resulting world feels si-
multaneously over-mediated and hollow because it is burning energy without performing
work.
65.1
The Inverse Relationship Between Trust and Technology
A mature civilization is not deﬁned by the quantity of technology it deploys, but by the
degree to which technology becomes unnecessary. Trust and mediation stand in an inverse
relationship.
Where trust is high, coordination requires little abstraction.
Where trust
collapses, mediation proliferates.
Primitive coordination regimes exhibit high trust and low mediation. They are local,
embodied, and ineﬃcient at scale, but they conserve meaning because identity, action, and
outcome remain tightly coupled. Intermediate regimes—the present global order—exhibit
low trust and high mediation. They scale symbolically but hemorrhage information. Identity
is abstracted, outcomes are obscured, and coordination is maintained through dashboards,
borders, contracts, surveillance, and persuasion.
A mature coordination regime restores high trust without reverting to locality. It achieves
this not through sentiment or homogeneity, but through traceable contribution. When ac-
tions leave durable logs, when outcomes are auditable, and when identity is conserved, trust
emerges mechanically. Mediation becomes redundant. Technology recedes into infrastructure
rather than spectacle.
This trajectory is not utopian. It is thermodynamically compelled. Systems that sub-
stitute mediation for trust incur ever-increasing energetic costs. Systems that restore trust
through conserved structure reduce those costs.
65.2
The Fake Junk Spiral as Thermal Noise
Within this framework, the proliferation of low-quality digital artifacts—what earlier sections
termed the fake junk spiral—appears in a new light. These artifacts are not merely culturally
debased content. They are thermal noise generated by an information system that lacks an
exhaust.
38

In a static-interface regime with low mobility and high mediation cost, agents are trapped
in local energy wells. They cannot relocate physically, logistically, or epistemically. Opti-
mization pressure therefore expresses itself symbolically. High-velocity, low-substance ar-
tifacts proliferate because there is no other available channel for dissipation. The system
overheats.
Attempts to suppress this noise through moderation or content ranking fail because they
treat symptoms rather than cause. Noise is not an aberration; it is the natural byproduct
of a closed system with blocked gradients. Only by restoring ﬂow—of people, work, and
information—can entropy be exported rather than accumulated.
65.3
The End of the Mid-Scale Abstraction
The nation-state and the advertising-driven platform emerge, in this analysis, as homologous
failures. They are mid-scale abstractions: too large to sustain high-trust coordination, yet
too small to manage global gradients of energy, labor, and information. Their persistence
produces artiﬁcial scarcity and necessitates ever-thickening mediation.
Borders function as binary gates in a system that requires gradients. Platforms function
as symbolic theaters in domains that require logs. Both sever agents from context and then
expend energy compensating for the resulting dislocation.
The alternative is not the elimination of structure, but its redeﬁnition. Coordination
units should be functional rather than territorial or symbolic. A jurisdiction is properly
deﬁned by the radius over which a high-ﬁdelity shared state can be maintained. If a group of
agents—human or artiﬁcial—can coordinate through a shared simulation, enforce invariants,
and preserve traceable contribution, they constitute a jurisdiction regardless of geography.
Such functional jurisdictions overlap, dissolve, and recombine as tasks change.
They
minimize mediation by aligning boundaries with actual coordination capacity rather than
historical accident.
65.4
The Integrity of the Object
The entire arc of this work returns, ﬁnally, to a single principle: meaning cannot be optimized
into existence. Optimization is a local process. It increases eﬃciency along a chosen metric
but often increases global entropy. Conservation is a global process. It preserves structure,
history, and the possibility of accumulation.
Civilization survives only insofar as it prioritizes the integrity of the object over the speed
of the symbol. The object may be a physical artifact, a skill, an ecosystem, or a shared model
39

of reality. Its integrity requires eﬀort, time, and constraint. Symbols—metrics, representa-
tions, interfaces—are useful only insofar as they remain subordinate to this integrity.
When symbols are allowed to outrun objects, simulation replaces participation. When
objects are conserved, symbols regain meaning.
65.5
Conclusion
The failures examined here—namespace laundering, metric detachment, null pedagogy, ar-
tiﬁcial scarcity, and excessive mediation—are not independent pathologies. They are mani-
festations of a single architectural error: the abandonment of conservation laws in favor of
symbolic liquidity.
The corrective is equally uniﬁed. A civilization that seeks to endure must design for
entropy minimization. It must conserve identity, eﬀort, and history. It must treat mobility as
adaptation, mediation as cost, and trust as an emergent property of traceable contribution. It
must build shared simulations rather than feeds, logs rather than dashboards, and functional
jurisdictions rather than static borders.
This is not a call for austerity or regression. It is a call for higher-ﬁdelity simplicity.
The future is not one of ever-thickening interfaces and accelerating symbols, but of thinning
mediation and deepening structure. Only such a civilization can reduce its waste heat of
coordination and convert energy, once again, into lasting work.
40

References
[1] C. E. Shannon. A Mathematical Theory of Communication. Bell System Technical
Journal, 27(3):379-423, 1948.
[2] R. Landauer.
Irreversibility and Heat Generation in the Computing Process.
IBM
Journal of Research and Development, 5(3):183-191, 1961.
[3] E. T. Jaynes.
Information Theory and Statistical Mechanics.
Physical Review,
106(4):620-630, 1957.
[4] T. M. Cover and J. A. Thomas. Elements of Information Theory. Wiley-Interscience,
2nd edition, 2006.
[5] C. A. E. Goodhart. Problems of Monetary Management: The U.K. Experience. In
Papers in Monetary Economics, Reserve Bank of Australia, 1975.
[6] M. Strathern. Improving Ratings: Audit in the British University System. European
Review, 5(3):305-321, 1997.
[7] H. A. Simon. The Architecture of Complexity. Proceedings of the American Philosophical
Society, 106(6):467-482, 1962.
[8] W. R. Ashby. An Introduction to Cybernetics. Chapman & Hall, 1956.
[9] S. Beer. Brain of the Firm. Allen Lane, 1972.
[10] N. Wiener. Cybernetics: Or Control and Communication in the Animal and the Ma-
chine. MIT Press, 1948.
[11] S. Zuboﬀ. The Age of Surveillance Capitalism. PublicAﬀairs, 2019.
[12] C. Doctorow. The Enshittiﬁcation of TikTok. Pluralistic, 2023.
[13] J. Lanier. Ten Arguments for Deleting Your Social Media Accounts Right Now. Henry
Holt, 2018.
[14] H. R. Varian. Artiﬁcial Intelligence, Economics, and Industrial Organization. In The
Economics of Artiﬁcial Intelligence, University of Chicago Press, 2019.
[15] E. Ostrom. Governing the Commons. Cambridge University Press, 1990.
[16] D. C. North. Institutions, Institutional Change, and Economic Performance. Cambridge
University Press, 1990.
41

[17] K. Polanyi. The Great Transformation. Beacon Press, 1944.
[18] C. Geertz. The Interpretation of Cultures. Basic Books, 1973.
[19] I. Illich. Tools for Conviviality. Harper & Row, 1973.
[20] I. Illich. Deschooling Society. Harper & Row, 1971.
[21] Z. Tufekci. Twitter and Tear Gas. Yale University Press, 2017.
[22] J. C. Scott. Seeing Like a State. Yale University Press, 1998.
[23] J. C. Scott. Against the Grain. Yale University Press, 2017.
[24] D. Kahneman. Thinking, Fast and Slow. Farrar, Straus and Giroux, 2011.
[25] K. Friston.
The Free-Energy Principle: A Uniﬁed Brain Theory?
Nature Reviews
Neuroscience, 11(2):127-138, 2010.
[26] C. P. Kempes et al. The Architecture of Life: Scaling Laws and Information Processing.
Physical Biology, 14(6), 2017.
[27] C. Perez. Technological Revolutions and Financial Capital. Edward Elgar, 2002.
[28] M. Gell-Mann. The Quark and the Jaguar. W. H. Freeman, 1994.
[29] C. S. Holling. Resilience and Stability of Ecological Systems. Annual Review of Ecology
and Systematics, 4:1-23, 1973.
[30] D. Meadows. Thinking in Systems. Chelsea Green, 2008.
[31] J. Ellul. The Technological Society. Knopf, 1964.
[32] J. R. Beniger. The Control Revolution. Harvard University Press, 1986.
[33] L. Floridi. The Fourth Revolution. Oxford University Press, 2014.
[34] G. Bateson. Steps to an Ecology of Mind. Ballantine Books, 1972.
[35] C. Kelty. Two Bits: The Cultural Signiﬁcance of Free Software. Duke University Press,
2008.
[36] D. Graeber. Bullshit Jobs. Simon & Schuster, 2018.
[37] K. Raworth. Doughnut Economics. Chelsea Green, 2017.
42

[38] D. MacKenzie. An Engine, Not a Camera. MIT Press, 2006.
[39] N. Bostrom. Superintelligence. Oxford University Press, 2014.
[40] W. B. Arthur. Increasing Returns and Path Dependence in the Economy. University of
Michigan Press, 1994.
43

