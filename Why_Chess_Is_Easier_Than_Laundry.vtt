WEBVTT

00:00.000 --> 00:05.440
Welcome back to the Deep Dive. Today, we are doing something a little bit different.

00:05.720 --> 00:06.140
Oh, yeah.

00:06.400 --> 00:10.720
Yeah, we're not just looking at a piece of tech or, you know, some historical event.

00:10.940 --> 00:12.640
We are wrestling with a ghost.

00:13.040 --> 00:17.860
A ghost? That is a very dramatic way to start.

00:18.120 --> 00:21.600
It is, isn't it? But honestly, after spending the last few days with the paper,

00:21.820 --> 00:23.400
that's exactly what it feels like.

00:23.420 --> 00:25.300
Okay, I'm intrigued. What's the ghost?

00:25.660 --> 00:27.260
We're talking about difficulty.

00:27.260 --> 00:32.940
You know, that visceral feeling when you're trying to solve a math problem

00:32.940 --> 00:34.880
that just won't crack or learn a new language.

00:35.180 --> 00:37.500
And this is a big one for me personally.

00:38.120 --> 00:43.300
Trying to fold a fitted sheet without it looking like a crumpled ball of despair.

00:43.580 --> 00:47.320
The nemesis of laundry folders everywhere. The final box.

00:47.340 --> 00:49.480
Exactly. But here's the thing.

00:49.980 --> 00:55.260
We instinctively feel like difficulty is this heavy thing.

00:55.260 --> 00:57.640
We treat it like a physical property.

00:57.980 --> 01:01.700
Like calculus is heavy and tic-tac-toe is light.

01:01.860 --> 01:06.180
We treat it like weight that, you know, lives inside the task itself.

01:06.520 --> 01:09.060
Right. We treat difficulty like it's gravity.

01:09.260 --> 01:13.180
It's just there, an intrinsic property of the universe that you have to overcome.

01:13.560 --> 01:17.380
But we are looking at a paper today that says, absolutely not.

01:17.380 --> 01:21.480
That entire way of thinking is wrong.

01:21.780 --> 01:23.040
Not just a little bit off.

01:23.160 --> 01:25.560
No, not just slightly off. It's fundamentally backwards.

01:26.780 --> 01:32.780
The paper is titled, Noun-Free Cognition, Difficulty, Abstraction, and the Mobility of Computation

01:32.780 --> 01:36.400
by Flickshannon, published just this year, 2026.

01:36.740 --> 01:37.100
Right.

01:37.100 --> 01:40.640
And it starts with this central mystery that has bugged me for years.

01:41.460 --> 01:46.940
Why are experts so incredibly bad at predicting what computers will find hard?

01:47.580 --> 01:50.260
The paradox of predictable unpredictability.

01:50.540 --> 01:56.760
This is a fascinating place to start because it really, um, it exposes our arrogance as a species.

01:57.020 --> 01:57.680
It really does.

01:58.040 --> 01:59.740
I mean, think back to the 1990s.

01:59.780 --> 02:01.660
Think about Deep Blue versus Kasparov.

02:01.700 --> 02:02.660
Oh, yeah. Huge deal.

02:02.660 --> 02:04.740
The entire world held its breath.

02:05.240 --> 02:11.100
We truly believe that if a machine could conquer chess, this fortress of logic, strategy, and foresight,

02:11.420 --> 02:12.660
that intelligence was solved.

02:12.720 --> 02:13.660
They were at the finish line.

02:13.820 --> 02:19.220
We thought the rest folding shirts, walking upstairs, common sense, was just the easy cleanup work.

02:19.380 --> 02:20.840
We thought those things were trivial.

02:21.480 --> 02:26.460
We assume that because we do them without thinking, they must be, you know, computationally simple.

02:26.800 --> 02:27.140
Right.

02:27.460 --> 02:29.800
We mistook a calculator for a brain.

02:29.980 --> 02:30.240
Yeah.

02:30.240 --> 02:31.440
And now...

02:31.440 --> 02:33.140
Well, now it's a completely different story.

02:33.260 --> 02:36.900
My phone plays better chess than any human who has ever lived.

02:37.960 --> 02:41.240
It can beat a grandmaster while I'm scrolling through social media.

02:41.240 --> 02:54.040
But if I ask a robot, even a billion-dollar cutting-edge robot, to walk into a messy room and just tidy up or fold a warm towel...

02:54.040 --> 02:55.160
It has a nervous breakdown.

02:55.320 --> 02:55.760
It freezes.

02:55.880 --> 02:56.400
Freezes.

02:56.500 --> 02:59.060
It's the classic chess versus laundry paradox.

02:59.060 --> 03:07.300
We assume chess was hard and laundry was easy because we were judging difficulty based on what we find hard.

03:07.520 --> 03:10.800
We projected our own biological struggles onto the machine.

03:10.800 --> 03:20.680
And this paper argues that the reason we keep getting this wrong, why we have self-driving cars that can navigate highways at 70 miles per hour but get confused by a traffic cone...

03:20.680 --> 03:20.880
Right.

03:21.200 --> 03:23.280
...is because we think difficulty is a noun.

03:23.500 --> 03:24.580
We think it's a thing.

03:24.580 --> 03:29.200
And the mission today for this deep dive is to dismantle that.

03:29.200 --> 03:37.980
We need to stop seeing difficulty as a noun, as a static weight, and start seeing it as a relation, a moving target.

03:38.140 --> 03:40.160
A ghost that moves through the system.

03:40.580 --> 03:41.140
Precisely.

03:41.480 --> 03:44.960
If we can get our heads around this, we stop asking, why is this hard?

03:44.960 --> 03:48.100
And we start asking a much more interesting question.

03:48.200 --> 03:48.600
Which is?

03:48.960 --> 03:51.240
Where did the difficulty go?

03:51.420 --> 04:01.720
So let's unpack this difficulty is not weight idea because I have to be honest, when I'm lifting a 50-pound dumbbell, that's 50 pounds.

04:01.880 --> 04:02.300
Sure.

04:02.740 --> 04:03.540
Feels that way.

04:03.760 --> 04:05.100
It doesn't matter if I'm tired.

04:05.280 --> 04:06.500
It doesn't matter if I'm happy.

04:06.700 --> 04:07.920
It's 50 pounds.

04:08.240 --> 04:10.320
Gravity doesn't care about my feelings.

04:10.520 --> 04:10.700
Yeah.

04:11.040 --> 04:13.560
Are you saying a math problem isn't like a dumbbell?

04:13.560 --> 04:16.700
That is exactly what Flickshan is arguing.

04:16.980 --> 04:19.760
If difficulty were like weight, it would be intrinsic.

04:20.060 --> 04:22.000
It would live inside the math problem.

04:22.480 --> 04:24.760
But let's stick with that dumbbell for a second.

04:24.960 --> 04:25.240
Okay.

04:25.520 --> 04:26.260
Is it heavy?

04:26.740 --> 04:27.220
Yes.

04:28.120 --> 04:28.920
50 pounds.

04:29.100 --> 04:30.660
Is it heavy to a forklift?

04:30.960 --> 04:32.060
Well, no.

04:32.700 --> 04:34.080
To a forklift, it's nothing.

04:34.340 --> 04:38.100
Is it heavy if you are floating in the International Space Station?

04:38.220 --> 04:39.420
Okay, I see where you're going with this.

04:39.500 --> 04:40.500
It's weightless there.

04:40.720 --> 04:41.860
The mass is the same.

04:41.860 --> 04:47.020
The heaviness, the difficulty of lifting it, changed entirely because the context changed.

04:47.640 --> 04:50.240
The paper introduces a relational model.

04:50.780 --> 04:54.920
It says difficulty is actually a function of four variables interacting at once.

04:54.980 --> 04:56.760
You can't look at just the object.

04:56.860 --> 04:57.860
Okay, lay them on me.

04:58.080 --> 04:59.020
What are the four variables?

04:59.080 --> 05:00.600
First, you have the task.

05:00.940 --> 05:03.900
That's the abstract goal, like get from point A to point B.

05:04.180 --> 05:05.060
Okay, the task.

05:05.060 --> 05:06.680
Second, you have the system.

05:06.900 --> 05:10.860
That's you, or the computer, or the forklift, the thing doing the work.

05:11.000 --> 05:11.340
System.

05:11.620 --> 05:12.040
Got it.

05:12.300 --> 05:15.400
Third, and this is crucial, you have the prompt.

05:16.120 --> 05:17.100
We'll dig into that one.

05:17.160 --> 05:17.580
It's a prompt.

05:17.900 --> 05:18.420
And fourth.

05:18.500 --> 05:19.320
The environment.

05:20.520 --> 05:23.280
The context, the time, the energy available.

05:23.280 --> 05:27.200
Okay, let's break these down because usually we just lump them all together.

05:27.420 --> 05:28.440
Driving is hard.

05:28.920 --> 05:32.240
But under this model, driving isn't the difficulty.

05:32.640 --> 05:33.080
Exactly.

05:33.520 --> 05:34.200
Let's take driving.

05:34.440 --> 05:37.500
The task is navigate the vehicle to the destination.

05:38.080 --> 05:39.740
Pretty simple, abstractly.

05:39.820 --> 05:40.020
Sure.

05:40.020 --> 05:45.880
The system is a human with eyes, hands, and a brain that's evolved for certain things.

05:46.340 --> 05:48.460
The environment is the road conditions.

05:49.000 --> 05:51.480
So, driving a car is easy on a sunny day.

05:52.180 --> 05:53.400
The task is the same.

05:53.560 --> 05:54.120
I'm the same.

05:54.560 --> 05:56.220
But let's say a blizzard hits.

05:57.220 --> 05:58.780
Suddenly, the environment shifts.

05:59.140 --> 06:00.620
And what happens to the difficulty?

06:00.700 --> 06:01.320
It spikes.

06:02.340 --> 06:03.300
Through the roof.

06:04.140 --> 06:05.060
My knuckles turn white.

06:05.280 --> 06:06.140
I turn off the radio.

06:06.360 --> 06:07.000
I'm sweating.

06:07.000 --> 06:08.820
But did the task change?

06:08.820 --> 06:10.900
You're still just trying to get to the destination.

06:11.180 --> 06:11.380
No.

06:11.620 --> 06:12.280
Same task.

06:12.420 --> 06:13.400
Did the car change?

06:13.640 --> 06:13.940
No.

06:14.420 --> 06:20.520
The difficulty emerged from the friction between the system, you, and the environment.

06:20.800 --> 06:21.340
The snow.

06:21.560 --> 06:22.420
It's a mismatch.

06:22.540 --> 06:24.060
It is a profound mismatch.

06:24.140 --> 06:25.100
And the paper goes deeper.

06:25.760 --> 06:32.440
It argues that we constantly mistake our own compilations, our habits and tools, for the task itself.

06:32.620 --> 06:34.380
Okay, what do you mean by compilations?

06:34.380 --> 06:36.180
Think of them as shortcuts.

06:37.380 --> 06:37.860
Habits.

06:38.340 --> 06:39.020
Muscle memory.

06:39.660 --> 06:42.360
When the environment shifts, those tools stop working.

06:42.840 --> 06:45.680
And that mismatch is what we experience as hard.

06:46.000 --> 06:48.080
So difficulty isn't a thing you encounter.

06:48.420 --> 06:50.740
It's a signal that your tools just broke.

06:50.880 --> 06:52.020
That's a great way to put it.

06:52.300 --> 06:54.040
It's an error message from your brain.

06:54.620 --> 06:58.380
It's the sound of your internal software crashing against a new reality.

06:58.380 --> 07:01.760
I want to dig into that third variable you mentioned, the prompt.

07:02.180 --> 07:11.180
Because, honestly, when I hear prompt in 2026, I immediately think of typing into an AI chatbot.

07:11.760 --> 07:12.380
Of course.

07:12.760 --> 07:14.700
Write me a poem about a sad toaster.

07:14.980 --> 07:17.260
Generate an image of a cat in a spacesuit.

07:17.720 --> 07:18.520
That's a prompt.

07:18.800 --> 07:22.680
And that is exactly the cultural baggage this paper wants to strip away.

07:22.680 --> 07:29.360
We have narrowed the definition of prompt so much that we're missing its actual function in cognition.

07:29.980 --> 07:30.240
How so?

07:30.460 --> 07:38.900
If we only think of prompts as text we type into a box, we miss how the entire physical world prompts us constantly.

07:39.300 --> 07:41.140
So, de-narrow it for me.

07:41.440 --> 07:44.360
What is a prompt in this noun-free world?

07:44.720 --> 07:50.020
A prompt is any specification that partitions the world into given and unresolved.

07:50.200 --> 07:50.760
Whoa, okay.

07:50.760 --> 07:51.820
It's a boundary condition.

07:52.080 --> 07:55.900
It draws a line in the sand and says, everything behind this line is resolved.

07:56.200 --> 07:57.320
You don't need to think about it.

07:57.380 --> 07:59.260
Everything in front of the line, that's your problem.

07:59.380 --> 07:59.640
Okay.

07:59.780 --> 08:00.600
That's a bit abstract.

08:01.200 --> 08:02.000
Partitions the world.

08:02.760 --> 08:05.220
Can you give me a concrete example that isn't a chatbot?

08:05.460 --> 08:07.080
Think about a blueprint for a house.

08:07.280 --> 08:07.500
Okay.

08:08.120 --> 08:10.180
A big roll of paper with blue lines.

08:10.480 --> 08:12.100
A blueprint is a prompt.

08:13.020 --> 08:15.980
Think about the cognitive load required to build a house.

08:15.980 --> 08:24.960
You need to know the load-bearing capacity of the wood, the geometry of the roof pitch, the flow of the plumbing, the electrical layout.

08:25.040 --> 08:25.160
Right.

08:25.200 --> 08:25.800
It's massive.

08:26.000 --> 08:31.440
If a builder had to figure all that out from scratch on the morning of the build, nothing would ever get built.

08:31.520 --> 08:32.000
Exactly.

08:32.000 --> 08:40.680
Honestly, when a builder looks at a blueprint, the geometry of the house, the dimensions, the layout, that is all given.

08:40.820 --> 08:41.500
It's resolved.

08:41.740 --> 08:43.020
It's resolved structure.

08:43.020 --> 08:48.600
The builder doesn't have to derive the math of the roof pitch or decide where the bathroom goes.

08:49.080 --> 08:52.120
That cognitive load has been relegated to the paper.

08:52.300 --> 08:53.920
The paper is doing the thinking.

08:54.240 --> 08:57.320
The paper is holding the frozen thinking of the architect.

08:57.800 --> 09:01.300
The blueprint says, don't worry about the math, just cut the wood to this length.

09:01.900 --> 09:05.800
The builder's unresolved task is just the physical execution.

09:05.800 --> 09:13.480
So the blueprint prompts the construction by removing the need to be an architect in real time.

09:13.620 --> 09:15.540
It's like a time capsule of decision making.

09:15.660 --> 09:15.900
Yes.

09:16.080 --> 09:17.180
It's an act of relegation.

09:17.340 --> 09:19.760
And once you see this, you see prompts everywhere.

09:20.020 --> 09:20.400
There else.

09:20.840 --> 09:21.880
Take a musical score.

09:22.280 --> 09:22.780
Sheet music.

09:23.260 --> 09:25.100
Think about what a musician is doing.

09:25.620 --> 09:30.000
If you didn't have the score, you'd have to compose the music while playing it.

09:30.000 --> 09:36.260
You'd have to decide the melody, the rhythm, the harmony, the dynamics, all in real time.

09:36.400 --> 09:37.280
That's improvisation.

09:37.820 --> 09:39.120
And it's incredibly hard.

09:39.240 --> 09:41.680
It is a huge cognitive load.

09:42.340 --> 09:50.020
But the sheet music is a prompt that relegates the decision of what note comes next and how long do I hold it.

09:50.120 --> 09:50.780
I see.

09:51.060 --> 09:58.640
The composer took on the structural difficulty so the performer can focus on the performance difficulty, the emotion, the timbre, the timing.

09:58.640 --> 09:59.560
That's fascinating.

09:59.740 --> 10:05.840
So a prompt is basically a way of saying, here, ignore all this stuff so you can focus on this one little sliver.

10:06.000 --> 10:06.320
Yes.

10:06.680 --> 10:08.360
And here's the really cool part.

10:09.120 --> 10:12.600
The paper argues that physical objects can be prompts too.

10:12.880 --> 10:15.500
Wait, how can a physical object be a prompt?

10:15.540 --> 10:20.920
Have you ever done any woodworking or even just assembled, you know, IKEA furniture?

10:21.220 --> 10:22.400
I built some bookshelves.

10:22.780 --> 10:24.380
I used a jig to drill the holes.

10:24.500 --> 10:26.000
Perfect example, a jig.

10:26.000 --> 10:34.400
If you need to drill a hole in exactly the same spot on 10,000 boards, you could try to measure it every time with a ruler and a pencil.

10:34.900 --> 10:35.680
That would take forever.

10:36.100 --> 10:40.180
And I'd probably mess up half of them because my hand would shake or I'd misread the ruler.

10:40.340 --> 10:40.640
Right.

10:40.940 --> 10:47.480
That's a high difficulty task requiring intense focus, steady hands, and constant calculation.

10:48.000 --> 10:49.680
But what does the jig do?

10:50.060 --> 10:51.600
It's a clamp with a guide hole.

10:51.600 --> 10:55.540
You just shove the wood in until it hits the stopper and put the drill in the hole.

10:55.720 --> 10:55.960
Boom.

10:56.340 --> 10:56.600
Done.

10:57.060 --> 10:58.620
The jig is a physical prompt.

10:59.140 --> 11:01.160
It resolves the spatial alignment.

11:01.720 --> 11:04.100
It relegates the need for hand stability.

11:04.280 --> 11:06.520
The difficulty is just gone.

11:06.680 --> 11:13.920
The task drill the hole is technically the same, but the difficulty has vanished because the prompt changed the boundary conditions.

11:13.920 --> 11:18.400
This connects to something the paper mentioned about the interface of difficulty.

11:19.160 --> 11:23.480
It said that changing the prompt changes the difficulty without changing the task.

11:23.820 --> 11:24.140
Right.

11:24.340 --> 11:26.420
Imagine a spatial logic puzzle.

11:26.840 --> 11:34.160
If I describe it to you in text, block A is left of block B, which is above block C, it's really hard to solve.

11:34.340 --> 11:36.600
Your brain has to simulate the space.

11:36.740 --> 11:37.680
I hate those.

11:37.680 --> 11:43.060
Susan sits next to the person wearing red, but not opposite the person eating fish.

11:43.240 --> 11:44.840
My brain just shuts down.

11:44.940 --> 11:45.800
It feels impossible.

11:46.260 --> 11:50.620
But if I give you a diagram, a picture of the table with empty slots.

11:50.780 --> 11:51.040
Easy.

11:51.540 --> 11:51.880
Instant.

11:52.340 --> 11:53.200
I can just see it.

11:53.260 --> 11:54.240
I can just move things around.

11:54.400 --> 11:55.680
The task is identical.

11:56.980 --> 11:58.100
Find the seating arrangement.

11:58.740 --> 12:02.340
But the diagram prompt aligns with your visual processing system.

12:02.340 --> 12:07.620
It selects a pre-compiled affordance, your ability to see patterns instantly.

12:08.000 --> 12:08.940
And the text prompt.

12:09.400 --> 12:10.940
It mismatches your toolkit.

12:11.520 --> 12:16.180
It forces you to use your much slower, more energy-intensive logical brain.

12:16.620 --> 12:18.600
So is the puzzle hard?

12:19.180 --> 12:21.340
Or did I just give you a bad prompt?

12:21.560 --> 12:23.440
That is the key takeaway here, isn't it?

12:23.520 --> 12:23.740
Yeah.

12:23.920 --> 12:25.400
Prompts select our tools.

12:25.660 --> 12:25.960
Yes.

12:25.960 --> 12:31.960
If the prompt matches the tools we already have, our pre-compiled affordances, it feels easy.

12:32.340 --> 12:34.200
If it misses, it feels impossible.

12:34.460 --> 12:38.900
Which leads us directly into the mechanism of how we build those tools in the first place.

12:39.020 --> 12:41.860
The paper calls this abstraction as compilation.

12:42.340 --> 12:44.640
I have to admit, this is where I stumbled a bit in the reading.

12:45.280 --> 12:47.400
I know compilation from computer science.

12:47.520 --> 12:56.180
You write code in, like, English-ish words, and the compiler crunches it down into ones and zeros that the machine can run instantly.

12:56.180 --> 12:56.820
Correct.

12:57.100 --> 13:01.960
It turns a complex logical argument into a set of automatic instructions.

13:02.340 --> 13:04.420
It bundles it up.

13:04.520 --> 13:05.320
But I'm not a computer.

13:05.680 --> 13:06.620
I'm not running code.

13:06.760 --> 13:07.000
Yeah.

13:07.220 --> 13:10.040
So how does this apply to me driving to the grocery store?

13:10.300 --> 13:12.420
Think about when you first learned to drive.

13:12.540 --> 13:14.380
Do you remember that first day in the parking lot?

13:14.500 --> 13:15.340
Oh, God, yes.

13:16.060 --> 13:16.900
It was a nightmare.

13:17.100 --> 13:18.480
I was thinking about everything.

13:18.740 --> 13:20.200
How much pressure is on the gas?

13:20.300 --> 13:21.200
Where are my hands?

13:21.560 --> 13:22.960
Am I too close to the curb?

13:23.120 --> 13:24.460
What did the mirrors show?

13:24.460 --> 13:26.700
You were running interpreted code.

13:26.880 --> 13:31.280
You were processing every single line of data in real time.

13:31.960 --> 13:33.540
High cognitive load.

13:33.740 --> 13:34.440
High energy.

13:35.200 --> 13:36.860
You were exhausted after 20 minutes.

13:37.160 --> 13:38.100
Drenched in sweat.

13:38.180 --> 13:38.740
It was awful.

13:38.920 --> 13:43.100
But now you drive to work and sometimes you don't even remember doing it.

13:43.180 --> 13:45.900
You arrive and think, wait, did I stop at all the red lights?

13:46.160 --> 13:47.020
Ideally, I did.

13:47.180 --> 13:48.660
But yes, I know the feeling.

13:48.780 --> 13:49.220
It's automatic.

13:49.420 --> 13:51.340
It's just driving.

13:51.340 --> 13:54.240
That is because you have compiled the process.

13:54.840 --> 13:58.140
Press pedal is now a single atomic action for you.

13:58.540 --> 14:06.800
You are not thinking about the combustion engine, the fuel injection, the friction of the tires, or the hydraulic pressure in the brake lines.

14:07.280 --> 14:14.280
You have an interface, the pedal, and you trust that the underlying machinery will handle the physics.

14:14.480 --> 14:18.400
So my brain has zipped up all that complexity into a single file called go.

14:18.520 --> 14:19.100
Exactly.

14:19.100 --> 14:20.700
But here is the danger.

14:21.340 --> 14:24.200
And the paper calls this the informal theorem.

14:24.940 --> 14:27.560
No compilation remains optimal forever.

14:27.840 --> 14:33.720
Because unlike software, where the hardware doesn't change much, reality is a moving target.

14:34.000 --> 14:34.240
Right.

14:34.400 --> 14:36.900
The pedal abstraction works great on dry asphalt.

14:37.120 --> 14:38.960
The go file executes perfectly.

14:39.240 --> 14:42.260
But let's go back to that snowy day we talked about.

14:42.380 --> 14:45.560
Suddenly, press pedal does not equal go forward.

14:45.920 --> 14:47.760
It equals spin out and die.

14:47.760 --> 14:49.480
The compilation fails.

14:49.640 --> 14:50.940
The abstraction leaks.

14:51.180 --> 14:51.900
It breaks.

14:52.100 --> 14:53.500
And this is that moment of panic.

14:53.720 --> 14:54.840
You have to decompile.

14:55.480 --> 15:00.100
You have to suddenly remember that the car is a physical object interacting with a slippery surface.

15:00.320 --> 15:03.300
You have to pump the brakes, steer into the skid.

15:03.300 --> 15:06.580
You have to think about the physics again from first principles.

15:06.580 --> 15:13.640
And that re-exposure of the internal structure is what we experience as a sudden spike in difficulty.

15:13.640 --> 15:19.120
The paper suggests that expertise is actually a form of fragility because of this.

15:19.240 --> 15:20.220
Wait, hang on.

15:20.460 --> 15:21.720
Expertise is fragility.

15:22.060 --> 15:24.100
I thought experts were the robust ones.

15:24.300 --> 15:28.560
If I hire an expert driver, I expect them to handle the snow better than me.

15:28.560 --> 15:31.800
They can handle the snow because they have a compilation for snow.

15:32.060 --> 15:33.400
That's a pattern they've compiled.

15:33.900 --> 15:35.500
But think about it structurally.

15:36.300 --> 15:41.960
Experts are efficient because they have deep stacks of these compiled shortcuts.

15:42.220 --> 15:42.480
Okay.

15:42.720 --> 15:48.580
They can ignore 99% of the information because they have a prompt or a mental model that handles it.

15:48.660 --> 15:51.400
They see a pattern and they just run the snow program.

15:51.400 --> 15:57.820
But if the context shifts in a way that violates their hidden assumptions...

15:57.820 --> 16:03.300
Like a grandmaster chess player suddenly having to play on a board where the squares change color and gravity shift.

16:03.380 --> 16:03.760
Oh, wow.

16:03.860 --> 16:05.720
They often crash harder than a novice.

16:05.820 --> 16:08.400
Because the novice never had the shortcut to begin with.

16:08.700 --> 16:09.160
Exactly.

16:09.460 --> 16:11.800
The novice was already looking at the raw physics.

16:12.280 --> 16:13.280
They were already struggling.

16:13.560 --> 16:15.960
So the change in context isn't as jarring.

16:16.140 --> 16:21.340
The expert has to unlearn their shortcuts before they can even start solving the new problem.

16:21.720 --> 16:22.840
That makes so much sense.

16:23.020 --> 16:27.160
It's like when a software update changes the location of a button I use every single day.

16:27.280 --> 16:27.540
Right.

16:27.740 --> 16:30.120
I'm paralyzed for like 10 minutes trying to find it.

16:30.700 --> 16:36.180
My mom, who never learned where the button was in the first place, just looks for it and finds it.

16:36.500 --> 16:37.020
Precisely.

16:37.240 --> 16:41.560
Your expertise, your muscle memory, became an obstacle.

16:42.080 --> 16:43.520
It was a brittle compilation.

16:43.660 --> 16:47.380
This really explains the chess vs. Tetris thing we started with.

16:47.900 --> 16:49.620
This asymmetry of intelligence.

16:49.620 --> 16:54.480
The paper argues that chess was a socio-historical artifact.

16:54.900 --> 16:56.920
It's a bit of a burn on chess, honestly.

16:57.120 --> 16:57.500
It is.

16:57.580 --> 17:05.400
It basically says chess became the benchmark for intelligence just because it was hard for us in a very specific human way.

17:05.600 --> 17:10.100
It was hard because it required combinatorial, search-looking, many moves ahead.

17:10.500 --> 17:13.200
If I move here, he moved there, then I move there.

17:13.260 --> 17:14.660
Our working memory is small.

17:14.660 --> 17:15.580
It's tiny.

17:16.020 --> 17:18.840
We can't hold that many future states in our heads.

17:19.380 --> 17:25.620
That is difficult for a biological brain that evolved to hunt and gather and read facial expressions.

17:25.720 --> 17:26.640
Not to play chess.

17:26.760 --> 17:27.800
Not to play chess.

17:28.260 --> 17:31.860
But for a computer, that kind of search is trivial.

17:32.200 --> 17:33.340
It's just math.

17:33.660 --> 17:36.000
It's a closed system with rigid rules.

17:36.400 --> 17:39.880
Once we figured out the structure, we could externalize it.

17:40.060 --> 17:41.140
We could write a prompt.

17:41.500 --> 17:43.260
The chess engine that solved it.

17:43.260 --> 17:48.780
So once the structure aligned with the compilation, the difficulty just vanished.

17:49.420 --> 17:50.800
It wasn't inherently hard.

17:50.920 --> 17:52.480
It was just hard for meat brains.

17:52.960 --> 17:53.400
Precisely.

17:53.620 --> 17:54.880
But look at Tetris.

17:55.220 --> 17:57.840
Or even better, let's go back to folding that towel.

17:58.280 --> 18:00.180
Why is the towel so hard for the robot?

18:00.460 --> 18:03.080
I've watched videos of robots trying to fold laundry.

18:03.280 --> 18:03.800
It's painful.

18:03.980 --> 18:04.940
They move so slowly.

18:05.060 --> 18:05.700
They poke at it.

18:05.720 --> 18:06.320
They get tangled.

18:06.460 --> 18:06.660
Why?

18:06.760 --> 18:07.900
What's the core problem?

18:08.200 --> 18:10.600
I guess because the towel is soft.

18:10.700 --> 18:11.400
It flops.

18:11.400 --> 18:13.160
It changes shape every time you touch it.

18:13.260 --> 18:13.600
Right.

18:13.740 --> 18:18.080
It relies on real-time perception, motor loops, feedback from your fingertips.

18:18.860 --> 18:20.400
There is no rigid grid.

18:20.540 --> 18:22.660
You cannot just calculate the towel.

18:23.100 --> 18:24.380
You have to feel it.

18:24.540 --> 18:30.460
And humans have millions of years of evolution embodied compilations that handle that.

18:30.460 --> 18:37.520
We have compiled grasping a soft object so deeply that we don't even know how we do it.

18:38.020 --> 18:42.880
Try to explain to a robot how to hold a towel without crushing it or dropping it.

18:42.940 --> 18:43.140
Okay.

18:43.340 --> 18:46.220
Don't squeeze too hard, but don't squeeze too soft.

18:46.340 --> 18:47.820
That means nothing to a robot.

18:47.960 --> 18:49.220
That's a useless prompt.

18:49.220 --> 18:54.900
It involves millions of micro-adjustments per second based on tension sensors in your skin.

18:55.460 --> 19:00.760
For the machine, the towel is an uncompiled nightmare of physics simulations.

19:01.300 --> 19:03.360
For us, it's just... grab.

19:03.680 --> 19:05.860
This is the no final convergence argument.

19:05.860 --> 19:12.040
There is this belief in tech, I hear it all the time in Silicon Valley, that AI will eventually

19:12.040 --> 19:15.100
just catch up and everything will be easy for everyone.

19:15.500 --> 19:17.580
Machines will do what we do, we'll do what they do.

19:17.700 --> 19:20.680
And this paper says, no, that's a fundamental misunderstanding.

19:20.980 --> 19:22.480
There will always be an asymmetry.

19:22.640 --> 19:24.000
Because our histories are different.

19:24.180 --> 19:25.500
Our compilations are different.

19:25.500 --> 19:26.020
Yes.

19:26.620 --> 19:32.080
We are compiled for the savanna, for social nuance, for manipulated physical objects.

19:32.560 --> 19:36.140
Machines are compiled for symbol manipulation and massive data processing.

19:36.460 --> 19:41.780
We will always find different things hard because we are running on different legacy code.

19:41.980 --> 19:43.200
That makes so much sense.

19:43.740 --> 19:46.460
We aren't converging on some universal intelligence.

19:46.780 --> 19:50.200
We're just distinct systems with different easy buttons.

19:50.320 --> 19:50.840
Exactly.

19:50.840 --> 19:55.880
And this leads to a massive misunderstanding of technological progress.

19:56.280 --> 19:56.740
How so?

19:56.960 --> 19:59.720
We tend to think technology eliminates difficulty.

20:00.340 --> 20:03.400
We invented the dishwasher, so washing dishes is solved.

20:03.600 --> 20:06.580
We invented the internet, so communication is solved.

20:06.860 --> 20:11.680
But the paper argues for the conservation of complexity.

20:12.160 --> 20:14.440
Or rather, computational displacement.

20:14.680 --> 20:14.980
Right.

20:15.180 --> 20:17.340
It's not that the difficulty is destroyed.

20:17.460 --> 20:18.160
That's impossible.

20:18.380 --> 20:19.700
It's redistributed.

20:19.700 --> 20:21.260
It has to go somewhere.

20:21.760 --> 20:24.500
The example of the one-click purchase really hit home for me.

20:25.100 --> 20:28.220
On my end, as the user, I tap a glass screen.

20:28.720 --> 20:29.360
One second.

20:30.080 --> 20:31.040
Zero difficulty.

20:31.480 --> 20:33.240
Low assembly index for you?

20:33.440 --> 20:34.300
It's effortless.

20:34.480 --> 20:39.240
But for that one tap to result in a package at my door the next day, let's trace that difficulty.

20:39.360 --> 20:39.980
Where did it go?

20:40.420 --> 20:41.400
It didn't vanish.

20:41.580 --> 20:42.720
It exploded outward.

20:43.360 --> 20:47.460
To make your experience simple, the system had to absorb massive complexity.

20:47.460 --> 20:52.660
You need global logistics networks tracking millions of items in real time.

20:52.660 --> 20:59.280
You need server farms cooling themselves in the desert, consuming small cities' worth of electricity.

20:59.720 --> 21:00.160
I like it.

21:00.300 --> 21:04.400
You need cybersecurity teams fighting off hackers 24-7.

21:04.660 --> 21:09.940
You need version control for the app software, A-B testing, user support.

21:10.060 --> 21:12.020
It moved into the infrastructure layer.

21:12.020 --> 21:13.980
And it moved on to other people.

21:14.120 --> 21:15.640
Think about the warehouse worker.

21:15.760 --> 21:18.680
That's the hardening of the analog world the paper talks about.

21:18.800 --> 21:19.160
Yes.

21:19.720 --> 21:27.060
When you make the digital interface smooth and frictionless, you often make the physical reality harder, more brutal.

21:27.860 --> 21:35.040
The warehouse worker's job shifts from craftsmanship, or storekeeping, to becoming a component in the machine's logic.

21:35.040 --> 21:36.800
They're chasing the algorithm.

21:37.000 --> 21:40.400
The robot tells them where to go, how fast to walk, when to take a break.

21:40.840 --> 21:44.920
Their difficulty, the physical toll on their body increases to support my ease.

21:45.120 --> 21:47.020
The complexity got displaced onto them.

21:47.300 --> 21:51.400
And for the rest of us, look at the physical toll of these easy interfaces.

21:51.660 --> 21:55.540
We have interfaces optimized for symbols, screens, keyboards.

21:56.140 --> 21:57.400
And our bodies are screening.

21:58.080 --> 22:01.140
Carpal tunnel, tech neck, eye strain, anxiety.

22:01.140 --> 22:04.900
That is the difficulty returning to us in a different form.

22:05.240 --> 22:16.140
We removed the difficulty of walking to the store or hunting for food, but we replaced it with the difficulty of sedentary lifestyle management and attention fragmentation.

22:16.880 --> 22:19.020
Oh, the attention fragmentation is real.

22:19.320 --> 22:21.880
The paper calls this the paradox of efficiency.

22:22.280 --> 22:22.840
Exactly.

22:23.260 --> 22:28.220
Making things easier to start lowering the friction means we do them more often.

22:28.340 --> 22:29.480
I feel this with email.

22:29.480 --> 22:36.500
If sending an email cost $5 and took an hour to handwrite, I would send maybe one a week.

22:36.720 --> 22:37.360
I'd be thoughtful.

22:37.580 --> 22:39.000
But since it's free and instant.

22:39.240 --> 22:40.240
I get $500 a day.

22:41.040 --> 22:42.820
And I'm expected to answer them all.

22:43.060 --> 22:46.040
My entire day is managing this easy task.

22:46.520 --> 22:50.620
So what was hard to do, writing a letter is now easy.

22:50.880 --> 22:54.480
But what was easy managing your correspondence is now impossible.

22:55.300 --> 22:57.740
The difficulty shifted from execution to management.

22:57.740 --> 23:01.740
We are drowning in volume because we remove the friction of entry.

23:02.080 --> 23:05.400
This feels like a perfect segue into section five, the trap of metrics.

23:06.160 --> 23:08.560
Because how do we try to manage this volume?

23:08.720 --> 23:12.520
How do companies manage the 500 emails or the warehouse efficiency?

23:12.840 --> 23:13.400
We measure it.

23:13.480 --> 23:14.560
We count the emails.

23:14.820 --> 23:15.020
Yeah.

23:15.100 --> 23:16.000
We track productivity.

23:16.000 --> 23:19.360
And we run headfirst into Goodhart's Law.

23:20.100 --> 23:26.360
Now, usually when people talk about Goodhart's Law, when a measure becomes a target, it ceases to be a good measure.

23:26.760 --> 23:28.500
They treat it like a data problem.

23:28.600 --> 23:28.920
Right.

23:29.260 --> 23:30.920
Oh, we just picked the wrong KPI.

23:31.160 --> 23:33.020
If we find the right number, it'll work.

23:33.280 --> 23:36.920
But Flickshaw argues it's an evolutionary force.

23:37.000 --> 23:37.980
It's almost biological.

23:37.980 --> 23:41.420
It's about turning a process into a noun.

23:41.900 --> 23:42.980
Unpack that for me.

23:43.200 --> 23:44.140
Process to noun.

23:44.260 --> 23:44.440
Okay.

23:45.160 --> 23:46.640
Learning is a process.

23:47.200 --> 23:47.900
It's fluid.

23:48.200 --> 23:49.080
It's messy.

23:49.240 --> 23:50.340
It happens in your head.

23:50.520 --> 23:53.700
It involves failure and confusion and insight.

23:54.080 --> 23:56.440
But a bureaucracy can't manage learning.

23:56.740 --> 23:57.840
It's too ghostly.

23:57.960 --> 23:58.600
It's invisible.

23:58.900 --> 24:00.280
So they turn it into a noun.

24:01.120 --> 24:01.860
A test score.

24:01.920 --> 24:02.800
Or a line of code.

24:03.280 --> 24:04.320
Or a number of tickets closed.

24:04.320 --> 24:05.940
These are static snapshots.

24:06.080 --> 24:13.440
And once the system sets that noun as the goal, every actor in the system starts optimizing for the noun, not the process.

24:14.020 --> 24:17.620
This reminds me so much of my time working in a call center right out of college.

24:17.720 --> 24:18.160
Oh, I bet.

24:18.340 --> 24:19.080
We had a metric.

24:19.600 --> 24:20.500
Average handle time.

24:20.940 --> 24:22.800
We had to keep calls under three minutes.

24:23.140 --> 24:23.820
That was the noun.

24:24.120 --> 24:25.160
Let me guess what happened.

24:26.060 --> 24:31.480
Did you become incredibly efficient at solving complex problems in under 180 seconds?

24:31.640 --> 24:32.100
No.

24:32.100 --> 24:34.340
We started hanging up on people.

24:34.760 --> 24:37.760
If a problem sounded hard, we'd accidentally lose the connection.

24:38.280 --> 24:41.580
Or we'd solve the easy part and tell them to call back for the rest.

24:42.040 --> 24:43.160
You gamed the metric.

24:43.620 --> 24:45.680
We optimized the metric perfectly.

24:46.120 --> 24:47.260
Our times were great.

24:47.840 --> 24:52.780
But the underlying process, actually helping customers, was destroyed.

24:53.300 --> 24:53.820
Completely.

24:54.240 --> 24:56.700
Customer satisfaction must have tanked.

24:56.700 --> 24:57.880
It fell off a cliff.

24:58.440 --> 25:01.400
And that is the optimization death spiral.

25:02.200 --> 25:05.580
Because what did management do when they saw satisfaction drop?

25:05.900 --> 25:07.360
Did they remove the metric?

25:07.780 --> 25:08.640
No, of course not.

25:08.700 --> 25:09.620
They added a new layer.

25:09.720 --> 25:10.520
They added a new layer.

25:10.640 --> 25:16.220
They said, okay, you have to keep calls under three minutes, but the customer also has to give you a four-star rating.

25:16.300 --> 25:18.000
And now you have two metrics to game.

25:18.240 --> 25:20.260
You just beg people for good ratings.

25:20.260 --> 25:23.280
The complexity of the system has net increased.

25:23.800 --> 25:27.940
You have added rules to patch the holes created by your previous simplification.

25:28.400 --> 25:31.740
This explains why bureaucracies and tech stacks always get bloated.

25:32.300 --> 25:34.380
They are patching their own abstractions.

25:34.380 --> 25:39.300
They are chasing the ghost of the process they killed by turning it into a noun.

25:40.140 --> 25:41.700
That is actually kind of tragic.

25:42.000 --> 25:42.320
It is.

25:42.420 --> 25:43.640
It's a tragedy of structure.

25:43.900 --> 25:45.540
Nobody is evil in that scenario.

25:45.940 --> 25:48.180
The system just forces that behavior.

25:48.600 --> 25:49.560
But why do we do this?

25:49.640 --> 25:52.200
It seems like there is a physics to this behavior.

25:52.620 --> 25:53.980
Why do we always take the shortcut?

25:54.520 --> 25:56.100
Why do we always game the metric?

25:56.580 --> 25:59.860
The paper uses assembly theory to explain this.

25:59.860 --> 26:06.900
Now, we don't need to get into the heavy math, but the core principle is the assembly index.

26:07.240 --> 26:11.860
Which is basically, how many steps does it take to build this thing from its parts?

26:12.020 --> 26:12.360
Right.

26:12.680 --> 26:14.800
But the key insight is about selection.

26:15.720 --> 26:21.820
The rule of adaptive systems, whether it's evolution or a chemical reaction or a corporate team,

26:21.960 --> 26:25.460
is that they do not look for the global best solution.

26:25.760 --> 26:28.380
They don't look at the map and plan the optimal route.

26:28.380 --> 26:28.820
No.

26:29.180 --> 26:31.360
They look for the immediate lowest resistance.

26:32.060 --> 26:33.760
Imagine water flowing down a hill.

26:33.820 --> 26:34.060
Okay.

26:34.400 --> 26:36.500
The water doesn't look at the landscape and say,

26:36.680 --> 26:41.720
oh, if I go slightly uphill here over this ridge, I'll find a much faster route to the ocean later.

26:42.420 --> 26:42.720
No.

26:42.940 --> 26:43.800
It just goes down.

26:44.220 --> 26:44.700
Immediately.

26:45.240 --> 26:47.220
It follows the slope right in front of it.

26:47.400 --> 26:49.500
It takes the next easiest step.

26:49.920 --> 26:52.640
Even if that step leads it into a swamp instead of the ocean.

26:52.840 --> 26:53.320
Exactly.

26:53.940 --> 26:57.540
And in cognition, that means using a compiled abstraction.

26:57.540 --> 26:59.020
Using a shortcut.

26:59.020 --> 27:03.860
So if I'm a programmer, using a pre-made software library is easier now.

27:04.100 --> 27:06.200
It lowers my immediate assembly index.

27:06.600 --> 27:08.160
I don't have to write the code myself.

27:08.280 --> 27:11.100
But that library couples you to someone else's bugs.

27:11.360 --> 27:11.560
Yeah.

27:11.620 --> 27:12.600
It bloats your software.

27:12.800 --> 27:14.080
It creates technical debt.

27:14.380 --> 27:15.920
That is the shortcut trap.

27:16.180 --> 27:20.260
We lower the immediate effort, but we raise the long-term maintenance cost.

27:20.480 --> 27:23.560
We flow downhill into a swamp of complexity.

27:23.560 --> 27:25.300
And here's the scary part.

27:25.900 --> 27:28.940
Technological progress just gives us more shortcuts.

27:29.280 --> 27:30.080
Oh, right.

27:30.240 --> 27:35.820
Greater capability expands the number of pre-compiled libraries, tools, and AIs we can reach for.

27:35.940 --> 27:39.040
So we can build things faster, low immediate resistance.

27:39.040 --> 27:42.680
But we are building them out of black boxes we don't understand.

27:42.880 --> 27:47.440
So we are accelerating the redistribution of complexity into invisible layers.

27:47.440 --> 27:53.020
We are building a skyscraper out of bricks we didn't bake on a foundation we didn't pour.

27:53.440 --> 27:55.300
And wondering why it sways in the wind.

27:55.840 --> 28:00.060
This connects to the philosophy section of the paper, which I found surprisingly deep.

28:00.900 --> 28:03.080
The saying versus doing gap.

28:04.200 --> 28:06.580
This was in the appendix, but I found it profound.

28:06.820 --> 28:10.700
It connects to Ludwig Wittgenstein, the ghost of Wittgenstein.

28:10.860 --> 28:12.500
He's the meaning is use guy, right?

28:12.620 --> 28:13.360
Language games.

28:13.360 --> 28:13.880
Yes.

28:14.340 --> 28:18.420
He argued you can't define game or difficulty in a vacuum.

28:19.300 --> 28:22.520
The meaning comes from playing the game, from the context.

28:23.080 --> 28:25.160
But the paper adds this corollary.

28:25.880 --> 28:27.120
Saying is compression.

28:27.700 --> 28:29.160
Doing is construction.

28:29.480 --> 28:30.700
Saying is a pointer.

28:30.940 --> 28:31.640
What does that mean?

28:31.820 --> 28:33.180
Think about generative AI.

28:33.700 --> 28:35.680
Think about mid-journey or DALI.

28:35.960 --> 28:36.320
Okay.

28:36.320 --> 28:45.780
If I type the prompt, show me a photorealistic image of a suspension bridge connecting New York to London, the AI generates it in seconds.

28:46.160 --> 28:47.480
And it looks incredible.

28:47.640 --> 28:50.040
It has cables, towers, water, lighting.

28:50.140 --> 28:50.820
It's beautiful.

28:51.320 --> 28:52.400
But is it a bridge?

28:52.600 --> 28:52.840
No.

28:53.040 --> 28:53.580
It's a picture.

28:53.780 --> 28:54.780
It's worse than a picture.

28:54.940 --> 28:55.500
It's a pointer.

28:55.980 --> 28:59.760
If you tried to build from that image, the bridge would collapse instantly.

29:00.580 --> 29:03.240
The AI said bridge, but it didn't do bridge.

29:03.380 --> 29:10.700
It didn't resolve the gravity, the tension, the wind shear, the steel ratings, the cost of materials, the bedrock on the ocean floor.

29:11.060 --> 29:15.020
It pointed to the idea of a bridge without doing the work of the bridge.

29:15.260 --> 29:15.700
Exactly.

29:16.380 --> 29:20.500
Saying uses a pointer to a region of possibility space.

29:21.320 --> 29:24.460
Doing requires building the causal chain to get there.

29:24.460 --> 29:28.280
It requires resolving every single unresolved dependency.

29:28.280 --> 29:31.220
The paper argues this asymmetry is structural.

29:32.260 --> 29:35.240
It will always be easier to say something than to do it.

29:35.700 --> 29:38.840
Because language is a lossy compression of reality.

29:39.040 --> 29:40.280
It strips away the constraints.

29:41.100 --> 29:47.260
And as our tools improve, as we get better AI, we can say things with even higher fidelity.

29:47.780 --> 29:50.760
We can generate plans that look incredibly detailed.

29:50.960 --> 29:53.600
So the saying has become incredibly sophisticated.

29:53.840 --> 29:54.640
It looks like doing.

29:54.900 --> 29:55.720
But it isn't.

29:55.780 --> 29:57.120
The image is still just a pointer.

29:57.120 --> 29:59.200
It has zero structural integrity.

29:59.720 --> 30:02.280
This explains why project timelines are always wrong.

30:02.700 --> 30:03.380
Ideas are cheap.

30:03.620 --> 30:06.580
Ideas are cheap because they are nonified possibilities.

30:06.880 --> 30:07.640
They are just pointers.

30:08.400 --> 30:11.420
Execution is the re-exposure of all the hidden difficulty.

30:11.820 --> 30:14.520
And the paper suggests this gap is widening.

30:14.680 --> 30:21.880
We can imagine and prompt systems that are vastly more complex than what we can physically manage or execute.

30:21.880 --> 30:23.540
That is daunting.

30:24.260 --> 30:31.200
It feels like we are trapping ourselves in a hall of mirrors where everything looks easy but nothing actually works.

30:31.340 --> 30:32.240
It can feel that way.

30:32.340 --> 30:33.240
It's a real danger.

30:33.680 --> 30:35.220
So where does this leave us?

30:35.620 --> 30:46.920
I mean, if difficulty is this moving target, this relation, this ghost, if our metrics are lying to us and our shortcuts are traps, what does it mean to be smart?

30:46.920 --> 30:50.260
This is Section 8, Implications for Intelligence.

30:50.560 --> 30:51.720
We have to redefine it.

30:51.720 --> 30:57.220
The old definition was capacity to solve inherently hard problems, like chess.

30:57.680 --> 30:59.280
Which we know now doesn't exist.

30:59.480 --> 31:01.360
There are no inherently hard problems.

31:01.480 --> 31:04.360
There are only problems that mismatch your current tools.

31:04.560 --> 31:06.900
So the new definition, what is it?

31:07.060 --> 31:10.600
Intelligence is the capacity to navigate shifting boundaries.

31:11.120 --> 31:14.400
It is the ability to recompile when the environment changes.

31:14.580 --> 31:15.140
I love that.

31:15.140 --> 31:17.660
It's not about how fast you can run the code.

31:17.860 --> 31:21.100
It's about how fast you can rewrite it when the hardware melts.

31:21.320 --> 31:21.720
Exactly.

31:22.000 --> 31:23.960
It's about fluidity and adaptation.

31:24.460 --> 31:30.300
And the paper defines stupidity in a very interesting way, not as a lack of brain power.

31:30.520 --> 31:33.520
But as an overcommitment to obsolete abstractions.

31:33.860 --> 31:41.120
Being stuck in your old ways, insisting that the pedal still works even though you're on ice, that is stupidity.

31:41.460 --> 31:42.960
It's a rigidity of compilation.

31:42.960 --> 31:45.720
This has huge ethical consequences, too.

31:46.040 --> 31:47.380
The paper talks about fairness.

31:47.760 --> 31:48.340
It does.

31:48.880 --> 31:58.000
If difficulty is a relation between the task, the prompt, and your pre-compiled affordances, then you cannot judge two people by the same output.

31:58.200 --> 32:00.080
Because one person might have a scaffold.

32:01.460 --> 32:02.580
A better set of tools.

32:02.820 --> 32:03.240
Exactly.

32:03.240 --> 32:13.560
If I grew up with tutors, high-speed internet, a stable home, and fluent English, I have a massive stack of compiled abstractions that resolve difficulty for me.

32:13.760 --> 32:19.140
I can focus on the high-level task because the low-level survival stuff is given.

32:19.560 --> 32:20.840
It's been humbled for me.

32:20.840 --> 32:27.220
And if someone else is dealing with food insecurity, or a second language, or a noisy home, or lack of access?

32:27.460 --> 32:30.120
They are decompiling survival every single day.

32:30.240 --> 32:32.580
They are spending their cognitive energy on the given.

32:33.120 --> 32:35.980
So a task that is easy for me is hard for them.

32:36.100 --> 32:40.420
Not because I am smarter, but because my scaffolding is doing the heavy lifting.

32:40.420 --> 32:43.460
So fairness isn't about treating everyone the same.

32:43.680 --> 32:45.760
It's about looking at the compilation history.

32:46.380 --> 32:50.840
And recognizing that responsibility lies in the design of the system.

32:51.360 --> 32:52.800
The design of the prompts.

32:53.560 --> 32:57.680
Are we designing prompts that only work for people with a specific set of tools?

32:57.920 --> 32:59.220
That is a powerful shift.

32:59.600 --> 33:03.460
It moves the blame from the individual to the architecture.

33:03.460 --> 33:10.180
It forces us to ask, who is bearing the displaced complexity of our simple systems?

33:11.160 --> 33:12.080
So we've been on a journey.

33:12.220 --> 33:14.940
We started with the paradox of the robot folding laundry.

33:15.380 --> 33:17.760
The things we thought were easy are actually hard.

33:18.060 --> 33:18.180
Right.

33:18.680 --> 33:21.040
We realized difficulty isn't a weight.

33:21.320 --> 33:23.720
It's a relation between the system and the environment.

33:24.440 --> 33:29.720
We learned that prompts are boundaries that partition the world into given and unresolved.

33:30.380 --> 33:35.500
We saw that abstraction is just compilation that eventually breaks when the road gets icy.

33:35.880 --> 33:37.840
And that that's what difficulty feels like.

33:37.840 --> 33:42.420
We tracked the movement of complexity from the user interface into the infrastructure in the human body.

33:42.740 --> 33:46.420
And we saw how metrics turn processes into nouns and break them.

33:46.640 --> 33:48.440
A tour of noun-free cognition.

33:48.920 --> 33:50.120
So what now?

33:50.840 --> 33:52.720
The paper ends with a provocation.

33:53.380 --> 33:54.020
A so what?

33:54.840 --> 33:58.200
And it uses a metaphor that I think is perfect for wrapping this up.

33:58.620 --> 33:59.140
The ladder.

33:59.520 --> 34:00.560
The ladder metaphor.

34:01.300 --> 34:03.480
It's a nod to Wittgenstein again.

34:03.480 --> 34:06.580
He said that his philosophy was like a ladder.

34:07.420 --> 34:09.920
You use it to climb up to a new vantage point.

34:10.160 --> 34:11.300
But once you're up there...

34:11.300 --> 34:12.740
You can throw the ladder away.

34:12.900 --> 34:13.940
You don't need it anymore.

34:14.080 --> 34:21.380
You don't need to walk around reciting assembly index minimization or prompt boundary conditions in your daily life.

34:21.560 --> 34:23.160
You don't need the jargon.

34:23.320 --> 34:24.400
You just need the view.

34:24.700 --> 34:26.220
You just need to change your seeing.

34:26.220 --> 34:26.860
Exactly.

34:27.800 --> 34:30.720
The goal isn't to become a philosopher of difficulty.

34:31.440 --> 34:33.820
The goal is to notice the ghost.

34:34.480 --> 34:38.240
And the call to action is simple but radical.

34:38.640 --> 34:40.640
Stop trying to eliminate difficulty.

34:40.820 --> 34:42.000
It cannot be destroyed.

34:42.240 --> 34:43.580
That is the fundamental law.

34:43.680 --> 34:44.800
It can only be moved.

34:44.960 --> 34:46.920
And the goal isn't a frictionless world.

34:47.320 --> 34:47.680
No.

34:47.860 --> 34:50.780
That's a fantasy that leads to fragility and disaster.

34:51.060 --> 34:54.580
The goal is to consciously manage where you put the friction.

34:54.580 --> 34:59.880
Do you want the friction on the user, on the worker, on the environment, on the future?

35:00.600 --> 35:01.980
Because it has to go somewhere.

35:02.320 --> 35:03.160
The choice is where.

35:03.500 --> 35:06.360
So, to everyone listening, here's your final thought.

35:07.100 --> 35:09.900
The next time you are struggling with a task,

35:10.180 --> 35:14.020
whether it's a spreadsheet that won't balance a difficult conversation with a partner,

35:14.560 --> 35:16.940
or, yes, folding that fitted sheet,

35:17.960 --> 35:20.020
don't ask, why is this hard?

35:20.980 --> 35:23.640
Because this doesn't have a difficulty.

35:23.640 --> 35:29.440
Instead, ask, which of my compiled abstractions just stopped working?

35:29.660 --> 35:33.020
Or, even better, who moved the complexity onto me?

35:33.180 --> 35:34.260
That is the question.

35:34.460 --> 35:35.820
Thanks for diving deep with us.

35:35.980 --> 35:36.900
We'll see you in the next one.

35:36.980 --> 35:37.640
Keep recompiling.

35:37.640 --> 35:38.200
Keep compiling.

35:38.260 --> 35:38.720
Keep compiling.

